{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling\n",
    "\n",
    "This notebook contains commands for all necessary preparations before training models:\n",
    "\n",
    "- concatenate data into 3 datasets (train, test1, test2);\n",
    "- produce labels for cross-validation\n",
    "\n",
    "Note: indices for train/test splits are already provided with this repository, but user may recompute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../data/csv/')\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from initialization import concatenateSeparateToOneDF\n",
    "from initialization import filterLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(\n",
    "    dirnames_list,\n",
    "    mza=100., mzb=900., mz_step=1.,\n",
    "    polarity_index_in=None, polarity_index_out=None\n",
    "):\n",
    "\n",
    "    if polarity_index_in is None:\n",
    "        pos_ind_in, neg_ind_in = 0, 1\n",
    "    else:\n",
    "        pos_ind_in, neg_ind_in = polarity_index_in\n",
    "\n",
    "    if polarity_index_out is None:\n",
    "        pos_ind_out, neg_ind_out = 0, 1\n",
    "    else:\n",
    "        pos_ind_out, neg_ind_out = polarity_index_out\n",
    "\n",
    "    result = []\n",
    "    labels = []\n",
    "    expnm = []\n",
    "    for k_ex in range(len(dirnames_list)):\n",
    "        filename = list(filter(lambda x: x.endswith('.npz'), os.listdir(dirnames_list[k_ex])))\n",
    "        if len(filename) > 1:\n",
    "            print(\n",
    "                'Warning: %s contains multiple .npz files; %s selected' % (\n",
    "                    dirnames_list[k_ex],\n",
    "                    filename[0]\n",
    "                )\n",
    "            )\n",
    "        filename = filename[0]\n",
    "        current_expname = filename[::-1].split('.')[1][::-1]\n",
    "        df = np.load(dirnames_list[k_ex]+'/'+filename)\n",
    "        mz = df['mz']\n",
    "        rt = df['rt']\n",
    "        data = df['data']\n",
    "        labels += df['labels'].tolist()\n",
    "        expnm += [current_expname]*len(df['labels'])\n",
    "        posNpoints, posNsamples = data[pos_ind_in].shape\n",
    "        negNpoints, negNsamples = data[neg_ind_in].shape\n",
    "        for k_sample in range(posNsamples):\n",
    "            local_data = np.zeros([int((mzb - mza)//mz_step), 2])\n",
    "            for k_point in range(max(posNpoints, negNpoints)):\n",
    "                if k_point < posNpoints:\n",
    "                    mzind = np.trunc((mz[pos_ind_in][k_point] - mza)/mz_step)\n",
    "                    #mzind = np.round((mz[pos_ind_in][k_point] - mza)/mz_step)\n",
    "                    mzind = int(mzind)\n",
    "                    if (\n",
    "                        (mza > mz[pos_ind_in][k_point]) or\n",
    "                        (mzb <= mz[pos_ind_in][k_point]) or\n",
    "                        (data[pos_ind_in][k_point, k_sample] == 0.) or\n",
    "                        #(mzind >= int(np.round((mzb - mza)/mz_step))) or\n",
    "                        (mzind >= int(np.trunc((mzb - mza)/mz_step))) or\n",
    "                        (mzind < 0)\n",
    "                    ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        local_data[mzind, pos_ind_out] = max(\n",
    "                            local_data[mzind, pos_ind_out],\n",
    "                            data[pos_ind_in][k_point, k_sample],\n",
    "                            0\n",
    "                        )\n",
    "                if k_point < negNpoints:\n",
    "                    mzind = np.trunc((mz[neg_ind_in][k_point] - mza)/mz_step)\n",
    "                    #mzind = np.round((mz[neg_ind_in][k_point] - mza)/mz_step)\n",
    "                    mzind = int(mzind)\n",
    "                    if (\n",
    "                        (mza > mz[neg_ind_in][k_point]) or\n",
    "                        (mzb <= mz[neg_ind_in][k_point]) or\n",
    "                        (data[neg_ind_in][k_point, k_sample] == 0.) or\n",
    "                        #(mzind >= int(np.round((mzb - mza)/mz_step))) or\n",
    "                        (mzind >= int(np.trunc((mzb - mza)/mz_step))) or\n",
    "                        (mzind < 0)\n",
    "                    ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        #print(mz[neg_ind_in][k_point], mz[neg_ind_in][k_point]-mza)\n",
    "                        local_data[mzind, neg_ind_out] = max(\n",
    "                            local_data[mzind, neg_ind_out],\n",
    "                            data[neg_ind_in][k_point, k_sample],\n",
    "                            0\n",
    "                        )\n",
    "            result.append(local_data)\n",
    "\n",
    "    result = np.array(result)\n",
    "    labels = np.array(labels)\n",
    "    expnm = np.array(expnm)\n",
    "    return result, labels, expnm\n",
    "                \n",
    "def get_exdf(\n",
    "    dirnames, labels_filename, uninteresting_directories=None, uninteresting_column_prefixes=None\n",
    "):\n",
    "    if uninteresting_directories is None:\n",
    "        uninteresting_directories = []\n",
    "    if uninteresting_column_prefixes is None:\n",
    "        uninteresting_column_prefixes = []\n",
    "        \n",
    "    ex_dict = {\n",
    "        'experiment': [],\n",
    "        'label': [],\n",
    "        'name_pos': [],\n",
    "        'name_neg': []\n",
    "    }\n",
    "\n",
    "\n",
    "    m3samples = {}\n",
    "\n",
    "    for dirname in dirnames:\n",
    "        if dirname in uninteresting_directories:\n",
    "            continue\n",
    "        with open(data_dirname+dirname+'/'+labels_filename, 'r') as f:\n",
    "            tmp_labels = f.readlines()\n",
    "            tmp_labels = list(map(lambda x: x.replace('\\n', ''), tmp_labels))\n",
    "            tmp_labels = list(filter(lambda x: (len(x) > 0), tmp_labels))\n",
    "            tmp_labels = list(map(int, tmp_labels))\n",
    "            tmp_labels = list(filter(lambda x: x != -1, tmp_labels))\n",
    "        tmp_labels = np.array(tmp_labels)\n",
    "        ind1 = np.where(tmp_labels == -3)[0]\n",
    "        ind2 = np.where(tmp_labels != -3)[0]\n",
    "        m3flag = len(ind1) > 0\n",
    "        if m3flag:\n",
    "            tmp_labels = tmp_labels[ind2].tolist()\n",
    "        else:\n",
    "            tmp_labels = tmp_labels.tolist()\n",
    "        ex_dict['label'] += tmp_labels\n",
    "        ex_dict['experiment'] += [dirname]*len(tmp_labels)\n",
    "        for pol in ['pos', 'neg']:\n",
    "            df = pd.read_csv(data_dirname+dirname+'/'+pol+'.csv', skiprows=2)\n",
    "            data_columns = [\n",
    "                x for x in df.columns if not x.startswith(tuple(uninteresting_column_prefixes))\n",
    "            ]\n",
    "            data_columns = list(map(lambda x: x.replace('#', '_'), data_columns))\n",
    "            if m3flag:\n",
    "                data_columns = np.array(data_columns)\n",
    "                m3samples[dirname] = data_columns[ind1]\n",
    "                data_columns = data_columns[ind2].tolist()\n",
    "            if dirname.endswith('ex1.1'):\n",
    "                data_columns = list(map(lambda x: 'pr'+x, data_columns))\n",
    "            ex_dict['name_'+pol] += data_columns\n",
    "    exdf = pd.DataFrame(ex_dict)\n",
    "    return exdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Converting CSVs into NPZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/csv/'\n",
    "label_filename = 'labels.dat'\n",
    "prefix = 'ex'\n",
    "\n",
    "ex_dirnames = os.listdir(data_dirname)\n",
    "ex_dirnames = filter(lambda x: x.startswith(prefix), ex_dirnames)\n",
    "ex_dirnames = sorted(ex_dirnames)\n",
    "\n",
    "csv_filenames = ['pos', 'neg']\n",
    "skip_prefixes = ['Charge', 'Blank', 'blank', 'Flav', 'flav', 'Compound', 'Comp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, (3132, 78))\n",
      "(78, (4462, 78))\n",
      "(36, (3049, 36))\n",
      "(36, (3904, 36))\n",
      "(216, (3129, 216))\n",
      "(216, (3036, 216))\n",
      "(216, (3859, 216))\n",
      "(216, (2925, 216))\n",
      "(105, (3917, 105))\n",
      "(105, (1448, 105))\n",
      "(104, (3507, 104))\n",
      "(104, (2584, 104))\n",
      "(115, (2927, 115))\n",
      "(115, (2206, 115))\n",
      "(1636, (4843, 1636))\n",
      "(1636, (5977, 1636))\n",
      "(26, (2896, 26))\n",
      "(26, (1667, 26))\n",
      "(26, (1682, 26))\n",
      "(26, (1720, 26))\n"
     ]
    }
   ],
   "source": [
    "for k_ex in range(len(ex_dirnames)):\n",
    "    current_dirname = ex_dirnames[k_ex]\n",
    "    with open(data_dirname+current_dirname+'/'+label_filename, 'r') as f:\n",
    "        labels = f.readlines()\n",
    "        labels = list(map(lambda x: int(x.replace('\\n', '')), labels))\n",
    "        labels = list(filter(lambda x: x != -1, labels))\n",
    "    mz = []\n",
    "    rt = []\n",
    "    data = []\n",
    "    samples = []\n",
    "    for k_pol in range(len(csv_filenames)):\n",
    "        current_filename = csv_filenames[k_pol]+'.csv'\n",
    "        df = pd.read_csv(data_dirname+current_dirname+'/'+current_filename, skiprows=2)\n",
    "        columns = df.columns.values\n",
    "        columns = filter(lambda x: all([not x.startswith(y) for y in skip_prefixes]), columns)\n",
    "        df = df[columns]\n",
    "        mz.append(df.iloc[:, 0].values)\n",
    "        rt.append(df.iloc[:, 1].values)\n",
    "        data.append(df.values[:, 2:])\n",
    "        samples.append(columns[2:])\n",
    "        print(len(labels), df.values[:, 2:].shape)\n",
    "    np.savez_compressed(\n",
    "        data_dirname+current_dirname+'/'+current_dirname,\n",
    "        mz=mz, rt=rt, samples=samples, data=data,\n",
    "        csv_filenames=csv_filenames, labels=labels\n",
    "    )   \n",
    "\n",
    "    #del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stacking main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind_in = 0\n",
    "neg_ind_in = (pos_ind_in+1) % 2\n",
    "pos_ind_out = 1\n",
    "neg_ind_out = (pos_ind_out+1) % 2\n",
    "\n",
    "dirnames = [data_dirname+x for x in ex_dirnames[:-2]]\n",
    "result, labels, expnm = discretize(\n",
    "    dirnames,\n",
    "    mza=100., mzb=900., mz_step=1.,\n",
    "    polarity_index_in=(pos_ind_in, neg_ind_in),\n",
    "    polarity_index_out=(pos_ind_out, neg_ind_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2262,), (2262, 800, 2))\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "expnm = np.array(expnm)\n",
    "i = np.where(labels > 0)[0]\n",
    "print(labels[i].shape, result[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dirname = '../data/'\n",
    "save_filename = 'LCMS-IT-TOF.npz'\n",
    "np.savez_compressed(\n",
    "    save_dirname+save_filename, expnm=expnm[i], label=labels[i], data=result[i]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LCMS-IT-TOF.npz> successfully filtered into <dataset>\n",
      "<LCMS-IT-TOF.npz>: successfully filtered into <dataset_without_moc>.\n",
      "('Parts dataset: ', {0: 'bark', 1: 'buds', 2: 'flowers', 3: 'fructus', 4: 'leaves', 5: 'roots', 6: 'roots and rhizomes', 7: 'seeds'})\n"
     ]
    }
   ],
   "source": [
    "dirname = '../data/'\n",
    "save_filename = 'dataset'\n",
    "save_filename_without_moc = 'dataset_without_moc'\n",
    "filename_without_moc = 'dataset_without_moc.npz'\n",
    "\n",
    "main_dataset_filename = 'LCMS-IT-TOF.npz'\n",
    "\n",
    "filterLabels(main_dataset_filename, dirname, min_count=20, save_filename=save_filename)\n",
    "print \"<%s> successfully filtered into <%s>\" % (main_dataset_filename, save_filename)\n",
    "\n",
    "filterLabels(main_dataset_filename, dirname, min_count=1, save_filename=save_filename_without_moc)\n",
    "print \"<%s>: successfully filtered into <%s>.\" % (main_dataset_filename, save_filename_without_moc)\n",
    "\n",
    "\n",
    "filename_without_moc_parts = 'dataset_parts.npz'\n",
    "species_filename = 'species.csv'\n",
    "try:\n",
    "    df = pd.read_csv(dirname+species_filename)\n",
    "    labelMapperParts = {}\n",
    "    for k in xrange(len(df)):\n",
    "        labelMapperParts[df.iloc[k, 0]] = df.iloc[k, -1]\n",
    "except:\n",
    "    print \"No file %s in %s directory.\" % (species_filename, dirname)\n",
    "\n",
    "df = np.load(dirname+filename_without_moc)\n",
    "X, y = df['data'], df['label']\n",
    "y_new = map(lambda x: labelMapperParts[x], y)\n",
    "labelEncoder = LabelEncoder()\n",
    "y_new = labelEncoder.fit_transform(y_new)\n",
    "class_names = labelEncoder.classes_\n",
    "np.savez_compressed(\n",
    "    dirname+filename_without_moc_parts, data=X, label=y_new\n",
    ")\n",
    "print('Parts dataset: ', dict((i, class_names[i]) for i in range(len(class_names))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating CV indices [for prediction (species, part) class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/csv/'\n",
    "\n",
    "uninteresting_directories = [\n",
    "    'ex2.2', 'ex2.3'\n",
    "]\n",
    "\n",
    "dirnames = os.listdir(data_dirname)\n",
    "dirnames = list(filter(lambda x: x.startswith('ex'), dirnames))\n",
    "dirnames = list(filter(lambda x: not (x in uninteresting_directories), dirnames))\n",
    "dirnames = list(filter(lambda x: os.path.isdir(data_dirname+x), dirnames))\n",
    "dirnames = sorted(dirnames)\n",
    "\n",
    "uninteresting_column_prefixes = [\n",
    "    'Flav_all', 'Blank', 'blank', 'Compound', 'Comp', 'm/z', 'Charge', 'Retention time (min)'\n",
    "]\n",
    "\n",
    "labels_filename = 'labels.dat'\n",
    "\n",
    "exdf = get_exdf(\n",
    "    dirnames, labels_filename, uninteresting_directories, uninteresting_column_prefixes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name_neg</th>\n",
       "      <th>name_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>57</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment  label                 name_neg                 name_pos\n",
       "0      ex1.1     56  pr1_1k10_20ul_1_Seg1Ev2  pr1_1k10_20ul_1_Seg1Ev1\n",
       "1      ex1.1     56  pr1_1k10_20ul_2_Seg1Ev2  pr1_1k10_20ul_2_Seg1Ev1\n",
       "2      ex1.1     53  pr2_1k10_10ul_1_Seg1Ev2  pr2_1k10_10ul_1_Seg1Ev1\n",
       "3      ex1.1     53  pr2_1k10_10ul_2_Seg1Ev2  pr2_1k10_10ul_2_Seg1Ev1\n",
       "4      ex1.1     57  pr3_1k10_10ul_1_Seg1Ev2  pr3_1k10_10ul_1_Seg1Ev1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correctorCSV(x):\n",
    "    result, tail = x.split('_Seg', 1)\n",
    "    if 'ul_AutoMSMS' in result:\n",
    "        result = 'pr'+result\n",
    "    if 'G26' in result:\n",
    "        result = result.replace('G26', 'G25')\n",
    "    if '10rc_1k10_3' in result:\n",
    "        result = result.replace('10rc', '10c')\n",
    "    if ('c_1k10_' in result) and (result.endswith('r')):\n",
    "        result = result[:-1]\n",
    "    result += '_Seg' + tail\n",
    "    return result\n",
    "\n",
    "def corrector(x):\n",
    "    result, tail = x.split('_Seg', 1)\n",
    "    if '0_u' in result:\n",
    "        result = result.replace('0_u', '0u')\n",
    "    if '5_u' in result:\n",
    "        result = result.replace('5_u', '5u')\n",
    "    if (result == 'C52-1_13'):\n",
    "        result = result[:-2] + '3'\n",
    "    if (result == '15+_1k5_10ul_12'):\n",
    "        result = result[:-2] + '2'\n",
    "    if (result == '33_1k10_10ul_') or (result == '33h_1k10_10ul_'):\n",
    "        result += '6'\n",
    "    result += '_Seg' + tail\n",
    "    return result\n",
    "\n",
    "def corrector2(x):\n",
    "    if x in [\n",
    "        'pr1_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1',\n",
    "        'pr16_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1',\n",
    "        'pr18_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1',\n",
    "        'pr19_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1',\n",
    "        'pr35_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1',\n",
    "        'pr20_1k10_20ul_AutoMSMS_Pos__1_Seg1Ev1'\n",
    "    ]:\n",
    "        return x.replace('_20ul_', '_10ul_')\n",
    "    return x\n",
    "\n",
    "def trimmer(x):\n",
    "    result = x.split('_Seg')[0]\n",
    "    if 'AutoMSMS' in x:\n",
    "        result = x.split('_AutoMSMS')[0]\n",
    "        result += '_AutoMSMS'\n",
    "    if '0_u' in result:\n",
    "        result = result.replace('0_u', '0u')\n",
    "    if '5_u' in result:\n",
    "        result = result.replace('5_u', '5u')\n",
    "    if (result == 'C52-1_13'):\n",
    "        result = result[:-2] + '3'\n",
    "    if (result == '15+_1k5_10ul_12'):\n",
    "        result = result[:-2] + '2'\n",
    "    if (result == '33_1k10_10ul_') or (result == '33h_1k10_10ul_'):\n",
    "        result += '6'\n",
    "    return result\n",
    "\n",
    "exdf['name_neg'] = exdf['name_neg'].apply(corrector)\n",
    "exdf['name_pos'] = exdf['name_pos'].apply(corrector)\n",
    "\n",
    "exdf['name_neg'] = exdf['name_neg'].apply(correctorCSV)\n",
    "exdf['name_pos'] = exdf['name_pos'].apply(correctorCSV)\n",
    "exdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Name</th>\n",
       "      <th>Factor Value[year]</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Term Source REF</th>\n",
       "      <th>Term Accession Number</th>\n",
       "      <th>Characteristics[Organism]</th>\n",
       "      <th>Term Source REF.1</th>\n",
       "      <th>Term Accession Number.1</th>\n",
       "      <th>Characteristics[Organism part]</th>\n",
       "      <th>Term Source REF.2</th>\n",
       "      <th>Term Accession Number.2</th>\n",
       "      <th>Protocol REF</th>\n",
       "      <th>Sample Name</th>\n",
       "      <th>Factor Value[location]</th>\n",
       "      <th>Term Source REF.3</th>\n",
       "      <th>Term Accession Number.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_treatment</td>\n",
       "      <td>2016</td>\n",
       "      <td>year</td>\n",
       "      <td>CCONT</td>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000036</td>\n",
       "      <td>Melilotus officinalis</td>\n",
       "      <td>NCBITAXON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leaf</td>\n",
       "      <td>BTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sample collection</td>\n",
       "      <td>10-1_1_Seg1Ev1</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_treatment</td>\n",
       "      <td>2016</td>\n",
       "      <td>year</td>\n",
       "      <td>CCONT</td>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000036</td>\n",
       "      <td>Melilotus officinalis</td>\n",
       "      <td>NCBITAXON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leaf</td>\n",
       "      <td>BTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sample collection</td>\n",
       "      <td>10-1_1_Seg1Ev2</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_treatment</td>\n",
       "      <td>2016</td>\n",
       "      <td>year</td>\n",
       "      <td>CCONT</td>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000036</td>\n",
       "      <td>Melilotus officinalis</td>\n",
       "      <td>NCBITAXON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leaf</td>\n",
       "      <td>BTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sample collection</td>\n",
       "      <td>10-1_2_Seg1Ev1</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_treatment</td>\n",
       "      <td>2016</td>\n",
       "      <td>year</td>\n",
       "      <td>CCONT</td>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000036</td>\n",
       "      <td>Melilotus officinalis</td>\n",
       "      <td>NCBITAXON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leaf</td>\n",
       "      <td>BTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sample collection</td>\n",
       "      <td>10-1_2_Seg1Ev2</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_treatment</td>\n",
       "      <td>2016</td>\n",
       "      <td>year</td>\n",
       "      <td>CCONT</td>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000036</td>\n",
       "      <td>Melilotus officinalis</td>\n",
       "      <td>NCBITAXON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leaf</td>\n",
       "      <td>BTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sample collection</td>\n",
       "      <td>10-1_3_Seg1Ev1</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Name  Factor Value[year]  Unit Term Source REF  \\\n",
       "0  no_treatment                2016  year           CCONT   \n",
       "1  no_treatment                2016  year           CCONT   \n",
       "2  no_treatment                2016  year           CCONT   \n",
       "3  no_treatment                2016  year           CCONT   \n",
       "4  no_treatment                2016  year           CCONT   \n",
       "\n",
       "                       Term Accession Number Characteristics[Organism]  \\\n",
       "0  http://purl.obolibrary.org/obo/UO_0000036     Melilotus officinalis   \n",
       "1  http://purl.obolibrary.org/obo/UO_0000036     Melilotus officinalis   \n",
       "2  http://purl.obolibrary.org/obo/UO_0000036     Melilotus officinalis   \n",
       "3  http://purl.obolibrary.org/obo/UO_0000036     Melilotus officinalis   \n",
       "4  http://purl.obolibrary.org/obo/UO_0000036     Melilotus officinalis   \n",
       "\n",
       "  Term Source REF.1 Term Accession Number.1 Characteristics[Organism part]  \\\n",
       "0         NCBITAXON                     NaN                           leaf   \n",
       "1         NCBITAXON                     NaN                           leaf   \n",
       "2         NCBITAXON                     NaN                           leaf   \n",
       "3         NCBITAXON                     NaN                           leaf   \n",
       "4         NCBITAXON                     NaN                           leaf   \n",
       "\n",
       "  Term Source REF.2 Term Accession Number.2       Protocol REF  \\\n",
       "0               BTO                     NaN  Sample collection   \n",
       "1               BTO                     NaN  Sample collection   \n",
       "2               BTO                     NaN  Sample collection   \n",
       "3               BTO                     NaN  Sample collection   \n",
       "4               BTO                     NaN  Sample collection   \n",
       "\n",
       "      Sample Name Factor Value[location]  Term Source REF.3  \\\n",
       "0  10-1_1_Seg1Ev1             Altai Krai                NaN   \n",
       "1  10-1_1_Seg1Ev2             Altai Krai                NaN   \n",
       "2  10-1_2_Seg1Ev1             Altai Krai                NaN   \n",
       "3  10-1_2_Seg1Ev2             Altai Krai                NaN   \n",
       "4  10-1_3_Seg1Ev1             Altai Krai                NaN   \n",
       "\n",
       "   Term Accession Number.3  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dirname+'s_plant_species_ident.txt', sep='\\t')\n",
    "df['Sample Name'] = df['Sample Name'].apply(corrector)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name_neg</th>\n",
       "      <th>name_pos</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>57</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment  label                 name_neg                 name_pos  \\\n",
       "0      ex1.1     56  pr1_1k10_20ul_1_Seg1Ev2  pr1_1k10_20ul_1_Seg1Ev1   \n",
       "1      ex1.1     56  pr1_1k10_20ul_2_Seg1Ev2  pr1_1k10_20ul_2_Seg1Ev1   \n",
       "2      ex1.1     53  pr2_1k10_10ul_1_Seg1Ev2  pr2_1k10_10ul_1_Seg1Ev1   \n",
       "3      ex1.1     53  pr2_1k10_10ul_2_Seg1Ev2  pr2_1k10_10ul_2_Seg1Ev1   \n",
       "4      ex1.1     57  pr3_1k10_10ul_1_Seg1Ev2  pr3_1k10_10ul_1_Seg1Ev1   \n",
       "\n",
       "      treatment  \n",
       "0  no_treatment  \n",
       "1  no_treatment  \n",
       "2  no_treatment  \n",
       "3  no_treatment  \n",
       "4  no_treatment  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_pos = list(\n",
    "    map(\n",
    "        lambda x: dict(name_pos=x, treatment=df[df['Sample Name'] == x]['Source Name'].values[0]),\n",
    "        exdf.name_pos\n",
    "    )\n",
    ")\n",
    "\n",
    "treatment_neg = list(\n",
    "    map(\n",
    "        lambda x: dict(name_neg=x, treatment=df[df['Sample Name'] == x]['Source Name'].values[0]),\n",
    "        exdf.name_neg\n",
    "    )\n",
    ")\n",
    "\n",
    "tmp_dfpos = pd.DataFrame(treatment_pos)\n",
    "tmp_dfneg = pd.DataFrame(treatment_neg)\n",
    "\n",
    "assert np.all(tmp_dfpos.treatment.values == tmp_dfneg.treatment.values)\n",
    "assert np.all(tmp_dfpos.name_pos.values == exdf.name_pos.values)\n",
    "\n",
    "exdf['treatment'] = tmp_dfpos.treatment.values\n",
    "exdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 2262)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name_neg</th>\n",
       "      <th>name_pos</th>\n",
       "      <th>treatment</th>\n",
       "      <th>sample_pos</th>\n",
       "      <th>trial_pos</th>\n",
       "      <th>sample_neg</th>\n",
       "      <th>trial_neg</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr1_1k10_20ul_no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr1_1k10_20ul_no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr2_1k10_10ul_no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr2_1k10_10ul_no_treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>57</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr3_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr3_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr3_1k10_10ul_no_treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment  label                 name_neg                 name_pos  \\\n",
       "0      ex1.1     56  pr1_1k10_20ul_1_Seg1Ev2  pr1_1k10_20ul_1_Seg1Ev1   \n",
       "1      ex1.1     56  pr1_1k10_20ul_2_Seg1Ev2  pr1_1k10_20ul_2_Seg1Ev1   \n",
       "2      ex1.1     53  pr2_1k10_10ul_1_Seg1Ev2  pr2_1k10_10ul_1_Seg1Ev1   \n",
       "3      ex1.1     53  pr2_1k10_10ul_2_Seg1Ev2  pr2_1k10_10ul_2_Seg1Ev1   \n",
       "4      ex1.1     57  pr3_1k10_10ul_1_Seg1Ev2  pr3_1k10_10ul_1_Seg1Ev1   \n",
       "\n",
       "      treatment     sample_pos trial_pos     sample_neg trial_neg  \\\n",
       "0  no_treatment  pr1_1k10_20ul         1  pr1_1k10_20ul         1   \n",
       "1  no_treatment  pr1_1k10_20ul         2  pr1_1k10_20ul         2   \n",
       "2  no_treatment  pr2_1k10_10ul         1  pr2_1k10_10ul         1   \n",
       "3  no_treatment  pr2_1k10_10ul         2  pr2_1k10_10ul         2   \n",
       "4  no_treatment  pr3_1k10_10ul         1  pr3_1k10_10ul         1   \n",
       "\n",
       "                       sample  \n",
       "0  pr1_1k10_20ul_no_treatment  \n",
       "1  pr1_1k10_20ul_no_treatment  \n",
       "2  pr2_1k10_10ul_no_treatment  \n",
       "3  pr2_1k10_10ul_no_treatment  \n",
       "4  pr3_1k10_10ul_no_treatment  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exdf['name_pos'] = exdf['name_pos'].apply(corrector2)\n",
    "\n",
    "exdf['sample_pos'] = exdf['name_pos'].apply(trimmer)\n",
    "exdf['trial_pos'] = exdf['sample_pos'].apply(lambda x: x[::-1].split('_', 1)[0][::-1])\n",
    "exdf['sample_pos'] = exdf['sample_pos'].apply(lambda x: x[::-1].split('_', 1)[1][::-1])\n",
    "\n",
    "exdf['sample_neg'] = exdf['name_neg'].apply(trimmer)\n",
    "exdf['trial_neg'] = exdf['sample_neg'].apply(lambda x: x[::-1].split('_', 1)[0][::-1])\n",
    "exdf['sample_neg'] = exdf['sample_neg'].apply(lambda x: x[::-1].split('_', 1)[1][::-1])\n",
    "\n",
    "tmp = np.char.array(exdf['sample_neg'].values)\n",
    "tmp = tmp + '_'\n",
    "tmp = tmp + np.char.array(exdf['treatment'].values)\n",
    "exdf['sample'] = tmp\n",
    "print(len(np.unique(tmp)), len(exdf))\n",
    "exdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n"
     ]
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "labels_unique = list(set(exdf.label.values))\n",
    "exdf['label'] = exdf['label'].astype('i')\n",
    "k = 0\n",
    "for i in range(len(labels_unique)):\n",
    "    label = labels_unique[i]\n",
    "    tmp = exdf[exdf['label']==label]\n",
    "    samples_unique = np.unique(tmp['sample'].values)\n",
    "    cur_dict = {}\n",
    "    for j in range(len(samples_unique)):\n",
    "        ind = tmp[tmp['sample'] == samples_unique[j]].index.values\n",
    "        cur_dict[samples_unique[j]] = ind\n",
    "    labels_dict[label] = cur_dict\n",
    "\n",
    "phys_labels = []\n",
    "for i in range(len(labels_unique)):\n",
    "    key = labels_unique[i]\n",
    "    phys_labels += [key]*len(labels_dict[key])\n",
    "print(len(phys_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "data_filename = 'dataset.npz'\n",
    "\n",
    "labels_init = np.load(data_dirname+data_filename)['label']\n",
    "labels_actual_unique = np.unique(labels_init)\n",
    "def labelMapper(x):\n",
    "    if x in labels_actual_unique:\n",
    "        return x\n",
    "    return -1\n",
    "\n",
    "exdf['label_actual'] = exdf['label'].map(labelMapper)\n",
    "labels_actual_dict = {}\n",
    "for i in range(len(labels_actual_unique)):\n",
    "    label = labels_actual_unique[i]\n",
    "    tmp = exdf[exdf['label_actual']==label]\n",
    "    samples_unique = np.unique(tmp['sample'].values)\n",
    "    cur_dict = {}\n",
    "    for j in range(len(samples_unique)):\n",
    "        ind = tmp[tmp['sample'] == samples_unique[j]].index.values\n",
    "        cur_dict[samples_unique[j]] = ind\n",
    "    labels_actual_dict[label] = cur_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "(9.758620689655173, 2.4373579658309357)\n"
     ]
    }
   ],
   "source": [
    "phys_labels_actual = []\n",
    "sample_names = []\n",
    "for i in range(len(labels_actual_unique)):\n",
    "    key = labels_actual_unique[i]\n",
    "    phys_labels_actual += [key]*len(labels_actual_dict[key])\n",
    "    sample_names.append(labels_actual_dict[key].keys())\n",
    "print(len(phys_labels_actual))\n",
    "uni_actual, cnt_actual = np.unique(phys_labels_actual, return_counts=True)\n",
    "print(np.mean(cnt_actual[1:]), np.std(cnt_actual[1:], ddof=1))\n",
    "\n",
    "np.savez_compressed(\n",
    "    data_dirname+'physical', phys_labels_actual=phys_labels_actual, labels_actual_dict=labels_actual_dict,\n",
    "    sample_names=sample_names\n",
    ")\n",
    "\n",
    "snm = reduce(lambda x, y: x+y, sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "n_repeats=5\n",
    "random_state=235\n",
    "filename='physical_cv_indices_nc'\n",
    "data_dirname = '../data/'\n",
    "\n",
    "y = phys_labels_actual\n",
    "X = np.empty([len(y), 0])\n",
    "\n",
    "kfold = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits,\n",
    "    n_repeats=n_repeats,\n",
    "    random_state=random_state\n",
    ")\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "np.random.seed(random_state)\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    phys_train_index = []\n",
    "    phys_test_index = []\n",
    "    for i in range(max(len(train_index), len(test_index))):\n",
    "        if i < len(train_index):\n",
    "            train_ind = train_index[i]\n",
    "            train_key = snm[train_ind]\n",
    "            i_train = y[train_ind]\n",
    "            phys_train_index += labels_actual_dict[i_train][train_key].tolist()\n",
    "        if i < len(test_index):\n",
    "            test_ind = test_index[i]\n",
    "            test_key = snm[test_ind]\n",
    "            i_test = y[test_ind]\n",
    "            phys_test_index.append(\n",
    "                np.random.choice(\n",
    "                    labels_actual_dict[i_test][test_key]\n",
    "                )\n",
    "            )\n",
    "    train_indices.append(phys_train_index)\n",
    "    test_indices.append(phys_test_index)\n",
    "    np.savez_compressed(\n",
    "        dirname+filename, n_splits=n_splits, n_repeats=n_repeats, random_state=random_state,\n",
    "        train_indices=train_indices, test_indices=test_indices\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generating CV indices [for prediction parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name_neg</th>\n",
       "      <th>name_pos</th>\n",
       "      <th>treatment</th>\n",
       "      <th>sample_pos</th>\n",
       "      <th>trial_pos</th>\n",
       "      <th>sample_neg</th>\n",
       "      <th>trial_neg</th>\n",
       "      <th>sample</th>\n",
       "      <th>label_actual</th>\n",
       "      <th>parts_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr1_1k10_20ul_no_treatment</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev2</td>\n",
       "      <td>pr1_1k10_20ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr1_1k10_20ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr1_1k10_20ul_no_treatment</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr2_1k10_10ul_no_treatment</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>53</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev2</td>\n",
       "      <td>pr2_1k10_10ul_2_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr2_1k10_10ul</td>\n",
       "      <td>2</td>\n",
       "      <td>pr2_1k10_10ul_no_treatment</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex1.1</td>\n",
       "      <td>57</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev2</td>\n",
       "      <td>pr3_1k10_10ul_1_Seg1Ev1</td>\n",
       "      <td>no_treatment</td>\n",
       "      <td>pr3_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr3_1k10_10ul</td>\n",
       "      <td>1</td>\n",
       "      <td>pr3_1k10_10ul_no_treatment</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment  label                 name_neg                 name_pos  \\\n",
       "0      ex1.1     56  pr1_1k10_20ul_1_Seg1Ev2  pr1_1k10_20ul_1_Seg1Ev1   \n",
       "1      ex1.1     56  pr1_1k10_20ul_2_Seg1Ev2  pr1_1k10_20ul_2_Seg1Ev1   \n",
       "2      ex1.1     53  pr2_1k10_10ul_1_Seg1Ev2  pr2_1k10_10ul_1_Seg1Ev1   \n",
       "3      ex1.1     53  pr2_1k10_10ul_2_Seg1Ev2  pr2_1k10_10ul_2_Seg1Ev1   \n",
       "4      ex1.1     57  pr3_1k10_10ul_1_Seg1Ev2  pr3_1k10_10ul_1_Seg1Ev1   \n",
       "\n",
       "      treatment     sample_pos trial_pos     sample_neg trial_neg  \\\n",
       "0  no_treatment  pr1_1k10_20ul         1  pr1_1k10_20ul         1   \n",
       "1  no_treatment  pr1_1k10_20ul         2  pr1_1k10_20ul         2   \n",
       "2  no_treatment  pr2_1k10_10ul         1  pr2_1k10_10ul         1   \n",
       "3  no_treatment  pr2_1k10_10ul         2  pr2_1k10_10ul         2   \n",
       "4  no_treatment  pr3_1k10_10ul         1  pr3_1k10_10ul         1   \n",
       "\n",
       "                       sample  label_actual  parts_label  \n",
       "0  pr1_1k10_20ul_no_treatment            56            5  \n",
       "1  pr1_1k10_20ul_no_treatment            56            5  \n",
       "2  pr2_1k10_10ul_no_treatment            53            6  \n",
       "3  pr2_1k10_10ul_no_treatment            53            6  \n",
       "4  pr3_1k10_10ul_no_treatment            57            5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exdf['parts_label'] = exdf['label'].map(labelMapperParts)\n",
    "exdf['parts_label'] = labelEncoder.transform(exdf['parts_label'])\n",
    "exdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n"
     ]
    }
   ],
   "source": [
    "parts_labels_unique = np.unique(exdf['parts_label'])\n",
    "parts_labels_dict = {}\n",
    "for i in range(len(parts_labels_unique)):\n",
    "    label = parts_labels_unique[i]\n",
    "    tmp = exdf[exdf['parts_label']==label]\n",
    "    samples_unique = np.unique(tmp['sample'].values)\n",
    "    cur_dict = {}\n",
    "    for j in range(len(samples_unique)):\n",
    "        ind = tmp[tmp['sample'] == samples_unique[j]].index.values\n",
    "        cur_dict[samples_unique[j]] = ind\n",
    "    parts_labels_dict[label] = cur_dict\n",
    "\n",
    "phys_parts_labels = []\n",
    "parts_sample_names = []\n",
    "for i in range(len(parts_labels_unique)):\n",
    "    key = parts_labels_unique[i]\n",
    "    phys_parts_labels += [key]*len(parts_labels_dict[key])\n",
    "    parts_sample_names.append(parts_labels_dict[key].keys())\n",
    "print(len(phys_parts_labels))    \n",
    "psnm = reduce(lambda x, y: x+y, parts_sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_without_moc_parts_cv = 'physical_cv_indices_parts'\n",
    "\n",
    "n_splits = 4\n",
    "n_repeats = 5\n",
    "# next variable must guarantee the quivalence of generated splits and ones used\n",
    "# in our research\n",
    "random_state = 235\n",
    "\n",
    "y = phys_parts_labels\n",
    "X = np.empty([len(y), 0])\n",
    "\n",
    "kfold = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits,\n",
    "    n_repeats=n_repeats,\n",
    "    random_state=random_state\n",
    ")\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "np.random.seed(random_state)\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    phys_parts_train_index = []\n",
    "    phys_parts_test_index = []\n",
    "    for i in range(max(len(train_index), len(test_index))):\n",
    "        if i < len(train_index):\n",
    "            train_ind = train_index[i]\n",
    "            train_key = psnm[train_ind]\n",
    "            i_train = y[train_ind]\n",
    "            phys_parts_train_index += parts_labels_dict[i_train][train_key].tolist()\n",
    "        if i < len(test_index):\n",
    "            test_ind = test_index[i]\n",
    "            test_key = psnm[test_ind]\n",
    "            i_test = y[test_ind]\n",
    "            phys_parts_test_index.append(\n",
    "                np.random.choice(\n",
    "                    parts_labels_dict[i_test][test_key]\n",
    "                )\n",
    "            )\n",
    "    train_indices.append(phys_parts_train_index)\n",
    "    test_indices.append(phys_parts_test_index)\n",
    "    np.savez_compressed(\n",
    "        dirname+filename_without_moc_parts_cv, n_splits=n_splits, n_repeats=n_repeats,\n",
    "        random_state=random_state,\n",
    "        train_indices=train_indices, test_indices=test_indices, class_names=class_names\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stacking test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset2\n",
    "data_dirname = '../data/csv/'\n",
    "\n",
    "pos_ind_in = 0\n",
    "neg_ind_in = (pos_ind_in+1) % 2\n",
    "pos_ind_out = 1\n",
    "neg_ind_out = (pos_ind_out+1) % 2\n",
    "\n",
    "dirnames = [data_dirname+x for x in ex_dirnames[-2:]]\n",
    "result2, labels2, expnm2 = discretize(\n",
    "    dirnames,\n",
    "    mza=100., mzb=900., mz_step=1.,\n",
    "    polarity_index_in=(pos_ind_in, neg_ind_in),\n",
    "    polarity_index_out=(pos_ind_out, neg_ind_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ex2.2', 'ex2.3']\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/csv/'\n",
    "\n",
    "uninteresting_directories = [\n",
    "    'ex2.1'\n",
    "]\n",
    "\n",
    "dirnames = os.listdir(data_dirname)\n",
    "dirnames = list(filter(lambda x: x.startswith('ex2'), dirnames))\n",
    "dirnames = list(filter(lambda x: not (x in uninteresting_directories), dirnames))\n",
    "dirnames = list(filter(lambda x: os.path.isdir(data_dirname+x), dirnames))\n",
    "dirnames = sorted(dirnames)\n",
    "\n",
    "uninteresting_column_prefixes = [\n",
    "    'Flav_all', 'Blank', 'blank', 'Compound', 'Comp', 'm/z', 'Charge', 'Retention time (min)'\n",
    "]\n",
    "\n",
    "labels_filename = 'labels.dat'\n",
    "print(dirnames)\n",
    "\n",
    "exdf2 = get_exdf(\n",
    "    dirnames, labels_filename, uninteresting_directories, uninteresting_column_prefixes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/LCMS-IT-TOF_ethanol\n",
      "../data/LCMS-IT-TOF_methanol\n",
      "../data/LCMS-IT-TOF_water\n",
      "../data/Agilent_QqQ_ethanol\n",
      "../data/Agilent_QqQ_methanol\n",
      "../data/Agilent_QqQ_water\n",
      "<test2>: successfully concatenated.\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "save_filename2 = 'test2'\n",
    "\n",
    "def corrector3(x):\n",
    "    for char in ['_', '-']:\n",
    "        if char in x:\n",
    "            return x.split(char)[0]\n",
    "    return x\n",
    "\n",
    "def getEluentName(x):\n",
    "    markers = ['m', 'w']\n",
    "    for mark in markers:\n",
    "        #if x.endswith(mark):\n",
    "        if mark in x:\n",
    "            return mark\n",
    "    return 'e'\n",
    "\n",
    "exdf2['eluent'] = exdf2['name_neg'].map(getEluentName)\n",
    "assert np.all(exdf2['eluent'].values == exdf2['name_pos'].apply(getEluentName).values)\n",
    "\n",
    "exdf2['name_neg'] = exdf2['name_neg'].map(corrector3)\n",
    "exdf2['name_pos'] = exdf2['name_pos'].map(corrector3)\n",
    "\n",
    "equipment = {\n",
    "    'ex2.2': 'LCMS-IT-TOF',\n",
    "    'ex2.3': 'Agilent_QqQ'\n",
    "}\n",
    "eluent_dict = {\n",
    "    'w': 'water',\n",
    "    'm': 'methanol',\n",
    "    'e': 'ethanol'\n",
    "}\n",
    "\n",
    "\n",
    "for j_key in equipment:\n",
    "    for i_key in eluent_dict:\n",
    "        ind = np.where(\n",
    "            (\n",
    "                (exdf2.eluent.values == i_key) &\n",
    "                (exdf2['experiment'] == j_key)\n",
    "            ).values == True\n",
    "        )[0]\n",
    "        current_expnm = exdf2.iloc[ind].values\n",
    "        current_label = labels2[ind]\n",
    "        assert np.all(current_label == exdf2.label.iloc[ind].values)\n",
    "        np.savez_compressed(\n",
    "            data_dirname+equipment[j_key]+'_'+eluent_dict[i_key],\n",
    "            label=current_label,\n",
    "            expnm=current_expnm,\n",
    "            data=result2[ind]\n",
    "        )\n",
    "        print data_dirname+equipment[j_key]+'_'+eluent_dict[i_key]\n",
    "\n",
    "additional_dataset_filenames = [\n",
    "    'LCMS-IT-TOF_water.npz', 'LCMS-IT-TOF_methanol.npz', \n",
    "    'Agilent_QqQ_water.npz', 'Agilent_QqQ_methanol.npz', 'Agilent_QqQ_ethanol.npz'\n",
    "]\n",
    "\n",
    "concatenateSeparateToOneDF(additional_dataset_filenames, data_dirname, save_filename2)\n",
    "print \"<%s>: successfully concatenated.\" % (save_filename2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test2 = 'test2.npz'\n",
    "filename_test2_parts = 'test2_parts'\n",
    "dirname = '../data/'\n",
    "\n",
    "df = np.load(dirname+filename_test2)\n",
    "Xtest2, ytest2 = df['data'], df['label']\n",
    "ytest2_new = map(lambda x: labelMapperParts[x], ytest2)\n",
    "ytest2_new = labelEncoder.transform(ytest2_new)\n",
    "#class_names = labelEncoder.classes_\n",
    "np.savez_compressed(\n",
    "    dirname+filename_test2_parts, data=Xtest2, label=ytest2_new\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
