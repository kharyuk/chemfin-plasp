{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [1. Imports](#Imports)\n",
    "- [2. Train models with fixed rank for CV](#Train-models-with-fixed-rank-for-CV )\n",
    "- [3. Predict with learned models](#Predict-with-learned-models)\n",
    "- [4. Rank selection: build models](#Rank-selection:-build-models)\n",
    "- [5. Rank selection: inspect accuracy](#Rank-selection:-inspect-accuracy)\n",
    "\n",
    "[Back to Chemfin](../Chemfin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The first cell with code includes almost all necessary inputs.\n",
    "\n",
    "Required packages: [numpy](http://www.numpy.org/), [scikit-learn](http://scikit-learn.org/), [dcor](https://pypi.python.org/pypi/dcor).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=8\n",
      "env: MKL_NUM_THREADS=8\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=8\n",
    "%env MKL_NUM_THREADS=8\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from computational_utils import reshape\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tucker import estimateMzPolarityFactors\n",
    "from tucker import TuckerClassifierLCMS\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import dcor\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models with fixed rank for CV\n",
    "\n",
    "It is assumed that CV indices has been already precomputed with [Initialize](./1_Initialize.ipynb).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind=0 rank=25 time=28321.34s\n",
      "ind=1 rank=25 time=31873.51s\n",
      "ind=2 rank=25 time=32788.16s\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "#filename_cv = 'cv_indices.npz'\n",
    "filename_cv = 'physical_cv_indices_nc.npz'\n",
    "maxitnum = 1000\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "    tic = time.clock()\n",
    "    clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "    toc = time.clock()\n",
    "    tms.append(toc-tic)\n",
    "    clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "    np.savez_compressed(\n",
    "        model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "        tms=tms\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "        ind, rank_mz, tms[-1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with learned models\n",
    "Principle angle used as measure of distance between two column-spaces.\n",
    "Requires additional imports of sklearn metrics.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=25_model_td_0.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hariyuki/apd/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/hariyuki/apd/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind=0 rank=25 time=875.21s/83.42s acc=0.9760/0.7208/0.8636 f1=0.9761/0.7135/0.9211\n",
      "rankMZ=25_model_td_1.npz\n",
      "ind=1 rank=25 time=916.62s/75.94s acc=0.9846/0.8000/0.8636 f1=0.9847/0.7959/0.9211\n",
      "rankMZ=25_model_td_2.npz\n",
      "ind=2 rank=25 time=937.53s/61.44s acc=0.9839/0.8195/0.8182 f1=0.9841/0.8093/0.8850\n",
      "rankMZ=25_model_td_3.npz\n",
      "ind=3 rank=25 time=947.11s/53.59s acc=0.9813/0.7965/0.7955 f1=0.9816/0.7877/0.8537\n",
      "rankMZ=25_model_td_4.npz\n",
      "ind=4 rank=25 time=1008.11s/49.56s acc=0.9802/0.7757/0.8409 f1=0.9801/0.7657/0.9053\n",
      "rankMZ=25_model_td_5.npz\n",
      "ind=5 rank=25 time=891.58s/85.68s acc=0.9789/0.7273/0.8182 f1=0.9791/0.7133/0.8955\n",
      "rankMZ=25_model_td_6.npz\n",
      "ind=6 rank=25 time=927.99s/82.75s acc=0.9806/0.7862/0.8636 f1=0.9808/0.7636/0.9211\n",
      "rankMZ=25_model_td_7.npz\n",
      "ind=7 rank=25 time=958.98s/70.42s acc=0.9809/0.7594/0.8864 f1=0.9808/0.7471/0.9337\n",
      "rankMZ=25_model_td_8.npz\n",
      "ind=8 rank=25 time=950.80s/59.40s acc=0.9744/0.8407/0.8409 f1=0.9747/0.8272/0.8714\n",
      "rankMZ=25_model_td_9.npz\n",
      "ind=9 rank=25 time=966.80s/57.38s acc=0.9766/0.7477/0.8409 f1=0.9765/0.7158/0.8851\n",
      "rankMZ=25_model_td_10.npz\n",
      "ind=10 rank=25 time=867.80s/77.98s acc=0.9803/0.8312/0.8864 f1=0.9803/0.8150/0.9268\n",
      "rankMZ=25_model_td_11.npz\n",
      "ind=11 rank=25 time=872.37s/75.70s acc=0.9761/0.8138/0.8864 f1=0.9765/0.8010/0.9337\n",
      "rankMZ=25_model_td_12.npz\n",
      "ind=12 rank=25 time=894.51s/64.33s acc=0.9799/0.7519/0.8409 f1=0.9799/0.7498/0.9085\n",
      "rankMZ=25_model_td_13.npz\n",
      "ind=13 rank=25 time=946.97s/55.29s acc=0.9818/0.7434/0.8409 f1=0.9817/0.7135/0.8577\n",
      "rankMZ=25_model_td_14.npz\n",
      "ind=14 rank=25 time=959.95s/50.86s acc=0.9816/0.7850/0.7727 f1=0.9818/0.7740/0.8266\n",
      "rankMZ=25_model_td_15.npz\n",
      "ind=15 rank=25 time=861.00s/79.41s acc=0.9767/0.7403/0.8409 f1=0.9765/0.7384/0.9081\n",
      "rankMZ=25_model_td_16.npz\n",
      "ind=16 rank=25 time=849.13s/71.80s acc=0.9824/0.8069/0.8409 f1=0.9825/0.8088/0.9053\n",
      "rankMZ=25_model_td_17.npz\n",
      "ind=17 rank=25 time=935.07s/61.32s acc=0.9802/0.7744/0.7500 f1=0.9802/0.7645/0.8436\n",
      "rankMZ=25_model_td_18.npz\n",
      "ind=18 rank=25 time=925.73s/57.28s acc=0.9797/0.7522/0.8409 f1=0.9797/0.7415/0.8952\n",
      "rankMZ=25_model_td_19.npz\n",
      "ind=19 rank=25 time=960.28s/51.25s acc=0.9750/0.8037/0.8864 f1=0.9749/0.7794/0.9337\n",
      "rankMZ=25_model_td_20.npz\n",
      "ind=20 rank=25 time=871.01s/71.34s acc=0.9798/0.7857/0.8864 f1=0.9798/0.7702/0.9337\n",
      "rankMZ=25_model_td_21.npz\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "#filename_cv = 'cv_indices.npz'\n",
    "filename_cv = 'physical_cv_indices_nc.npz'\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset2)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "confusion_matrices = []\n",
    "\n",
    "predicted_pa_test = []\n",
    "predicted_pa_test2 = []\n",
    "\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r)\n",
    "    model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "    print model_filename\n",
    "    clf.loadParameters(model_dirname+model_filename)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_train_pred = clf.predict(X[train_indices[ind]])\n",
    "    toc = time.clock()\n",
    "    tms_loc = [toc-tic]\n",
    "    acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "    f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_test_pred, y_test_pred_explicit = clf.predict(X[test_indices[ind]], return_all=True)\n",
    "    toc = time.clock()\n",
    "    tms_loc.append(toc-tic)\n",
    "    conf_mat = confusion_matrix(y[test_indices[ind]], y_test_pred)\n",
    "    acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "    f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "    \n",
    "    y_test2_pred, y_test2_pred_explicit = clf.predict(X_test2, return_all=True)\n",
    "    acc_loc.append( accuracy_score(y_test2, y_test2_pred) )\n",
    "    f1_loc.append( f1_score(y_test2, y_test2_pred, average='weighted') )\n",
    "    \n",
    "    tms.append(tms_loc)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    \n",
    "    y_test_pred_explicit = y_test_pred_explicit.assign(TRUE=y[test_indices[ind]])\n",
    "    predicted_pa_test.append( y_test_pred_explicit.values )\n",
    "    y_test2_pred_explicit = y_test2_pred_explicit.assign(TRUE=y_test2)\n",
    "    predicted_pa_test2.append( y_test2_pred_explicit.values )\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rankMZ='+str(rank_mz)+model_filename_base+'+CCA',\n",
    "        tms=tms, confusion_matrices=confusion_matrices, accuracies=accuracies,\n",
    "        f1s=f1s, classes=clf.classes, predicted_pa_test=predicted_pa_test,\n",
    "        predicted_pa_test2=predicted_pa_test2\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs/%.2fs acc=%.4f/%.4f/%.4f f1=%.4f/%.4f/%.4f\" % (\n",
    "        ind, rank_mz, tms[-1][0], tms[-1][1], acc_loc[0], acc_loc[1], acc_loc[2],\n",
    "        f1_loc[0], f1_loc[1], f1_loc[2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample (from test) prediction time: 0.51 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.979911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.765732</td>\n",
       "      <td>0.905303</td>\n",
       "      <td>0.979879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      test     test2     train\n",
       "0  accuracy  0.785047  0.840909  0.979911\n",
       "1        F1  0.765732  0.905303  0.979879"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "rank = 25\n",
    "\n",
    "df = np.load( results_dirname+'rankMZ='+str(rank)+model_filename_base+'+CCA.npz' )\n",
    "\n",
    "\n",
    "accuracies = np.median(df['accuracies'], axis=0)\n",
    "f1s = np.median(df['f1s'], axis=0)\n",
    "tms = df['tms']\n",
    "\n",
    "numSampPerFold = map(lambda x: float(len(x)), test_indices)\n",
    "tms[:, 1] /= numSampPerFold\n",
    "\n",
    "tms = np.median(tms, axis=0)\n",
    "\n",
    "dataDict = {\n",
    "    'train': [accuracies[0], f1s[0]],\n",
    "    'test': [accuracies[1], f1s[1]],\n",
    "    'test2': [accuracies[2], f1s[2]],\n",
    "    'index': ['accuracy', 'F1']\n",
    "}\n",
    "\n",
    "print 'One sample (from test) prediction time: %.2f s' % (tms[1])\n",
    "\n",
    "table = pd.DataFrame(dataDict)\n",
    "table.set_index('index')\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample (from test) prediction time: 0.47 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.77931</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.97969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.76262</td>\n",
       "      <td>0.897998</td>\n",
       "      <td>0.97977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     test     test2    train\n",
       "0  accuracy  0.77931  0.840909  0.97969\n",
       "1        F1  0.76262  0.897998  0.97977"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: build models\n",
    "\n",
    "Grid search approach followed by inspection of accuracy (one times repeated K-fold)\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind=0 rank=1 time=70.01s\n",
      "ind=0 rank=2 time=324.70s\n",
      "ind=0 rank=3 time=542.91s\n",
      "ind=0 rank=4 time=1201.56s\n",
      "ind=0 rank=5 time=1712.20s\n",
      "ind=0 rank=6 time=2929.71s\n",
      "ind=0 rank=7 time=4452.68s\n",
      "ind=0 rank=8 time=5132.80s\n",
      "ind=0 rank=9 time=6621.87s\n",
      "ind=0 rank=10 time=7289.60s\n",
      "ind=0 rank=11 time=8276.01s\n",
      "ind=0 rank=12 time=9645.99s\n",
      "ind=0 rank=13 time=11372.01s\n",
      "ind=0 rank=14 time=12437.62s\n",
      "ind=0 rank=15 time=14299.24s\n",
      "ind=0 rank=16 time=13842.07s\n",
      "ind=0 rank=17 time=14949.49s\n",
      "ind=0 rank=18 time=15207.60s\n",
      "ind=0 rank=19 time=17285.15s\n",
      "ind=0 rank=20 time=19357.69s\n",
      "ind=0 rank=21 time=22528.68s\n",
      "ind=0 rank=22 time=21637.98s\n",
      "ind=0 rank=23 time=26229.13s\n",
      "ind=0 rank=24 time=26979.81s\n",
      "ind=0 rank=25 time=24437.93s\n",
      "ind=1 rank=1 time=95.13s\n",
      "ind=1 rank=2 time=612.36s\n",
      "ind=1 rank=3 time=853.66s\n",
      "ind=1 rank=4 time=1473.31s\n",
      "ind=1 rank=5 time=2529.90s\n",
      "ind=1 rank=6 time=4313.67s\n",
      "ind=1 rank=7 time=5164.87s\n",
      "ind=1 rank=8 time=6304.96s\n",
      "ind=1 rank=9 time=9310.80s\n",
      "ind=1 rank=10 time=11987.69s\n",
      "ind=1 rank=11 time=14162.58s\n",
      "ind=1 rank=12 time=14829.71s\n",
      "ind=1 rank=13 time=17919.45s\n",
      "ind=1 rank=14 time=19443.03s\n",
      "ind=1 rank=15 time=19774.54s\n",
      "ind=1 rank=16 time=22920.36s\n",
      "ind=1 rank=17 time=22525.92s\n",
      "ind=1 rank=18 time=24287.08s\n",
      "ind=1 rank=19 time=25584.89s\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "#filename_cv = 'cv_indices.npz'\n",
    "filename_cv = 'physical_cv_indices_nc.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "n_splits = 5\n",
    "\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(n_splits):\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "        tic = time.clock()\n",
    "        clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "        toc = time.clock()\n",
    "        tms.append(toc-tic)\n",
    "        clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "        np.savez_compressed(\n",
    "            model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "            tms=tms\n",
    "        )\n",
    "        print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "            ind, rank_mz, tms[-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: inspect accuracy\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=1_model_td_0.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hariyuki/apd/lib/python2.7/site-packages/dcor/_utils.py:88: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return ((np.issubdtype(x.dtype, float) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=2_model_td_0.npz\n",
      "rankMZ=3_model_td_0.npz\n",
      "rankMZ=4_model_td_0.npz\n",
      "rankMZ=5_model_td_0.npz\n",
      "rankMZ=6_model_td_0.npz\n",
      "rankMZ=7_model_td_0.npz\n"
     ]
    }
   ],
   "source": [
    "metrics = ['cca', 'dcor']\n",
    "\n",
    "metric_name = metrics[1]\n",
    "\n",
    "if metric_name == 'cca':\n",
    "    metric = None\n",
    "elif metric_name == 'dcor':\n",
    "    metric = dcor.distance_correlation\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "#filename_cv = 'cv_indices.npz'\n",
    "filename_cv = 'physical_cv_indices_nc.npz'\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "for ind in xrange(n_splits):\n",
    "    tms_l = []\n",
    "    accuracies_l = []\n",
    "    f1s_l = []\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        \n",
    "        clf = TuckerClassifierLCMS(Nmz, r)\n",
    "        model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "        print model_filename\n",
    "        clf.loadParameters(model_dirname+model_filename)\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_train_pred = clf.predict(X[train_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc = [toc-tic]\n",
    "        acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "        f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_test_pred = clf.predict(X[test_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc.append(toc-tic)\n",
    "        acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "        f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "\n",
    "\n",
    "        tms_l.append(tms_loc)\n",
    "        accuracies_l.append(acc_loc)\n",
    "        f1s_l.append(f1_loc)\n",
    "    accuracies.append(accuracies_l)\n",
    "    f1s.append(f1s_l)\n",
    "    tms.append(tms_l)\n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rank_selection_metric='+metric_name+'_'+model_filename_prefix+'+'+metric_name,\n",
    "        tms=tms, accuracies=accuracies, f1s=f1s\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "tms = np.array(tms)\n",
    "\n",
    "print \"Accuracies:\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"F1-measures:\"\n",
    "print np.median(f1s, axis=0)\n",
    "print \"Prediction time (for all samples):\"\n",
    "print np.median(np.sum(tms, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "[[0.43733333 0.33834586]\n",
      " [0.69262295 0.48051948]\n",
      " [0.69118414 0.4953271 ]\n",
      " [0.72954925 0.55862069]\n",
      " [0.73653396 0.56493506]\n",
      " [0.73419204 0.57142857]\n",
      " [0.74528841 0.57943925]\n",
      " [0.74700171 0.57943925]\n",
      " [0.74126239 0.56074766]\n",
      " [0.74346132 0.55172414]\n",
      " [0.72189696 0.53793103]\n",
      " [0.72676683 0.54482759]\n",
      " [0.72529983 0.55172414]\n",
      " [0.72482436 0.55862069]\n",
      " [0.721202   0.56551724]\n",
      " [0.71897607 0.55140187]\n",
      " [0.720726   0.56390977]\n",
      " [0.71311475 0.56493506]\n",
      " [0.71194379 0.54135338]\n",
      " [0.71253333 0.54887218]\n",
      " [0.70895938 0.53271028]\n",
      " [0.71721311 0.53246753]\n",
      " [0.71146667 0.54545455]\n",
      " [0.70474015 0.53271028]\n",
      " [0.72248244 0.55172414]]\n",
      "F1-measures:\n",
      "[[0.42402708 0.32614866]\n",
      " [0.71799773 0.47925063]\n",
      " [0.73309307 0.51305219]\n",
      " [0.76358876 0.57541959]\n",
      " [0.7869755  0.58786333]\n",
      " [0.7848737  0.60293754]\n",
      " [0.79814278 0.59773805]\n",
      " [0.805665   0.59279973]\n",
      " [0.79885924 0.5878348 ]\n",
      " [0.80584592 0.60085429]\n",
      " [0.79246676 0.56926705]\n",
      " [0.79560758 0.57813857]\n",
      " [0.79607765 0.58239875]\n",
      " [0.79740654 0.59489796]\n",
      " [0.79449954 0.58826967]\n",
      " [0.7957097  0.58049072]\n",
      " [0.79390333 0.60339841]\n",
      " [0.79108137 0.58839678]\n",
      " [0.78947324 0.57363864]\n",
      " [0.79044859 0.58642033]\n",
      " [0.78815191 0.56086005]\n",
      " [0.79844024 0.55996413]\n",
      " [0.79416467 0.58511185]\n",
      " [0.78642753 0.56283241]\n",
      " [0.80281086 0.58187351]]\n",
      "Prediction time (for all samples):\n",
      "[20760.705901 21166.082973 21400.877389 22215.234617 22532.270109\n",
      " 22457.90709  22973.389868 23157.263602 23574.912586 23379.842787\n",
      " 24285.194884 24478.811081 25417.452542 25170.22965  26332.649531\n",
      " 26187.690401 26607.223035 24256.583335 26615.190807 25109.044641\n",
      " 26751.047679 26752.784562 27124.945928 27036.977375 27957.791491]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracies:\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"F1-measures:\"\n",
    "print np.median(f1s, axis=0)\n",
    "print \"Prediction time (for all samples):\"\n",
    "print np.median(np.sum(tms, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look on components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_prefix = 'model_td_all'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "tic = time.clock()\n",
    "clf.fit(X, y, verbose=0)\n",
    "toc = time.clock()\n",
    "tms = toc-tic\n",
    "clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix)\n",
    "np.savez_compressed(\n",
    "    model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "    tms=tms\n",
    ")\n",
    "\n",
    "print 'Evaluation time: %.2f s' % (tms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=25_model_td_all.npz\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "eps = 10*np.spacing(1.)\n",
    "def func(i, A, B, Omega):\n",
    "    ii = int(i)\n",
    "    if (ii >= A.size) or (ii in Omega):\n",
    "        return +np.infty\n",
    "    rv = np.mean(np.abs(B[:, ii])) - np.log(eps+np.abs(A[ii]))\n",
    "    if np.isnan(rv):\n",
    "        return +np.infty\n",
    "    return rv\n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_all'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "rank = rank_mz, rank_pol\n",
    "n_comp = 3\n",
    "\n",
    "df = np.load(data_dirname + filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "clf = TuckerClassifierLCMS(Nmz, rank)\n",
    "model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+'.npz'\n",
    "print model_filename\n",
    "clf.loadParameters(model_dirname+model_filename)\n",
    "\n",
    "components = clf.MZspaces\n",
    "polspaces = clf.Polspaces_inv\n",
    "corrDict = {}\n",
    "#Z = X[test_indices[ind]].copy()\n",
    "# the first loop is for component spaces\n",
    "Omegas = {}\n",
    "for i_cl in xrange(len(clf.classes)):\n",
    "    tmp = []\n",
    "    current_component_class = clf.classes[i_cl]\n",
    "    # the second loop is for samples' classes\n",
    "    for j_cl in xrange(len(clf.classes)):\n",
    "        current_sample_class = clf.classes[j_cl]\n",
    "        which = np.where(y == current_sample_class)[0]\n",
    "        Z = np.einsum('ijk,kl->ijl', X[which], polspaces[current_component_class])\n",
    "        corrMat = np.corrcoef(Z.T[0], components[current_component_class], rowvar=False)\n",
    "        \n",
    "        corrMat += np.corrcoef(Z.T[1], components[current_component_class], rowvar=False)\n",
    "        corrMat *= 0.5\n",
    "        corrMat = corrMat[:len(which), len(which):]\n",
    "        \n",
    "        tmp.append( np.median(corrMat, axis=0) )\n",
    "    corrDict[current_component_class] = np.array(tmp)\n",
    "    spind = range(i_cl) + range(i_cl+1, len(clf.classes))\n",
    "    spind = tuple(spind)\n",
    "    Omega = []\n",
    "    f = lambda i: func(\n",
    "        i,\n",
    "        corrDict[current_component_class][i_cl, :],\n",
    "        corrDict[current_component_class][spind, :],\n",
    "        Omega\n",
    "    )\n",
    "    ranges = (slice(0, components[current_component_class].shape[1], 1),)\n",
    "    for l_c in xrange(n_comp):\n",
    "        p = scipy.optimize.brute(f, ranges)\n",
    "        p = int(p)\n",
    "        '''\n",
    "        print (\n",
    "            current_component_class,\n",
    "            corrDict[current_component_class][i_cl, p],\n",
    "            corrDict[current_component_class][:, p]\n",
    "        )\n",
    "        '''\n",
    "        Omega.append(p)\n",
    "    Omegas[current_component_class] = Omega\n",
    "\n",
    "np.savez_compressed(\n",
    "    model_dirname+'sntd_components', classes=clf.classes, components=components, Omegas=Omegas, \n",
    "    corrDict=corrDict\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
