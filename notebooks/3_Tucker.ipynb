{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [1. Imports](#Imports)\n",
    "- [2. Train models with fixed rank for CV](#Train-models-with-fixed-rank-for-CV )\n",
    "- [3. Predict with learned models](#Predict-with-learned-models)\n",
    "- [4. Rank selection: build models](#Rank-selection:-build-models)\n",
    "- [5. Rank selection: inspect accuracy](#Rank-selection:-inspect-accuracy)\n",
    "\n",
    "[Back to Chemfin](../Chemfin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The first cell with code includes almost all necessary inputs.\n",
    "\n",
    "Required packages: [numpy](http://www.numpy.org/), [scikit-learn](http://scikit-learn.org/), [dcor](https://pypi.python.org/pypi/dcor).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=4\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=4\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from computational_utils import reshape\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tucker import estimateMzPolarityFactors\n",
    "from tucker import TuckerClassifierLCMS\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import dcor\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models with fixed rank for CV\n",
    "\n",
    "It is assumed that CV indices has been already precomputed with [Initialize](./1_Initialize.ipynb).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind=0 rank=25 time=52826.16s\n",
      "ind=1 rank=25 time=52615.62s\n",
      "ind=2 rank=25 time=57755.90s\n",
      "ind=3 rank=25 time=52189.50s\n",
      "ind=4 rank=25 time=53416.44s\n",
      "ind=5 rank=25 time=51258.26s\n",
      "ind=6 rank=25 time=55868.38s\n",
      "ind=7 rank=25 time=50189.79s\n",
      "ind=8 rank=25 time=51762.45s\n",
      "ind=9 rank=25 time=55265.80s\n",
      "ind=10 rank=25 time=52065.07s\n",
      "ind=11 rank=25 time=50743.12s\n",
      "ind=12 rank=25 time=52441.37s\n",
      "ind=13 rank=25 time=56996.62s\n",
      "ind=14 rank=25 time=64201.51s\n",
      "ind=15 rank=25 time=54402.55s\n",
      "ind=16 rank=25 time=59769.03s\n",
      "ind=17 rank=25 time=59780.56s\n",
      "ind=18 rank=25 time=66703.53s\n",
      "ind=19 rank=25 time=57762.88s\n",
      "ind=20 rank=25 time=51917.56s\n",
      "ind=21 rank=25 time=50853.04s\n",
      "ind=22 rank=25 time=48563.67s\n",
      "ind=23 rank=25 time=54836.83s\n",
      "ind=24 rank=25 time=67458.81s\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "    tic = time.clock()\n",
    "    clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "    toc = time.clock()\n",
    "    tms.append(toc-tic)\n",
    "    clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "    np.savez_compressed(\n",
    "        model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "        tms=tms\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "        ind, rank_mz, tms[-1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with learned models\n",
    "Principle angle used as measure of distance between two column-spaces.\n",
    "Requires additional imports of sklearn metrics.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=25_model_td_0.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hariyuki/apd/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind=0 rank=25 time=2041.82s/540.80s acc=0.9776/0.9119/0.8636 f1=0.9779/0.9109/0.9110\n",
      "rankMZ=25_model_td_1.npz\n",
      "ind=1 rank=25 time=2019.48s/537.77s acc=0.9728/0.9502/0.8409 f1=0.9726/0.9497/0.8684\n",
      "rankMZ=25_model_td_2.npz\n",
      "ind=2 rank=25 time=2098.12s/508.57s acc=0.9746/0.9381/0.9091 f1=0.9747/0.9400/0.9495\n",
      "rankMZ=25_model_td_3.npz\n",
      "ind=3 rank=25 time=2129.23s/522.27s acc=0.9725/0.9438/0.8182 f1=0.9722/0.9437/0.8657\n",
      "rankMZ=25_model_td_4.npz\n",
      "ind=4 rank=25 time=2069.94s/488.21s acc=0.9788/0.9204/0.9091 f1=0.9792/0.9194/0.9495\n",
      "rankMZ=25_model_td_5.npz\n",
      "ind=5 rank=25 time=2049.69s/536.31s acc=0.9759/0.9539/0.8636 f1=0.9761/0.9543/0.9207\n",
      "rankMZ=25_model_td_6.npz\n",
      "ind=6 rank=25 time=2145.20s/563.02s acc=0.9795/0.9481/0.8636 f1=0.9795/0.9485/0.9211\n",
      "rankMZ=25_model_td_7.npz\n",
      "ind=7 rank=25 time=2100.96s/509.59s acc=0.9763/0.9336/0.8409 f1=0.9763/0.9335/0.9081\n",
      "rankMZ=25_model_td_8.npz\n",
      "ind=8 rank=25 time=2114.12s/511.10s acc=0.9780/0.9528/0.8864 f1=0.9781/0.9518/0.9337\n",
      "rankMZ=25_model_td_9.npz\n",
      "ind=9 rank=25 time=2120.18s/480.22s acc=0.9749/0.9321/0.8409 f1=0.9748/0.9332/0.8787\n",
      "rankMZ=25_model_td_10.npz\n",
      "ind=10 rank=25 time=2088.90s/529.94s acc=0.9798/0.9224/0.9318 f1=0.9798/0.9224/0.9621\n",
      "rankMZ=25_model_td_11.npz\n",
      "ind=11 rank=25 time=2110.26s/573.62s acc=0.9789/0.9372/0.8636 f1=0.9791/0.9372/0.9179\n",
      "rankMZ=25_model_td_12.npz\n",
      "ind=12 rank=25 time=2061.44s/523.92s acc=0.9707/0.9314/0.8864 f1=0.9707/0.9313/0.9369\n",
      "rankMZ=25_model_td_13.npz\n",
      "ind=13 rank=25 time=2102.78s/501.06s acc=0.9741/0.9146/0.8636 f1=0.9743/0.9146/0.9106\n",
      "rankMZ=25_model_td_14.npz\n",
      "ind=14 rank=25 time=2143.78s/500.52s acc=0.9798/0.9415/0.8182 f1=0.9800/0.9428/0.8955\n",
      "rankMZ=25_model_td_15.npz\n",
      "ind=15 rank=25 time=2039.51s/550.36s acc=0.9720/0.9224/0.8182 f1=0.9721/0.9234/0.8666\n",
      "rankMZ=25_model_td_16.npz\n",
      "ind=16 rank=25 time=2065.05s/531.29s acc=0.9745/0.9416/0.8864 f1=0.9746/0.9420/0.9369\n",
      "rankMZ=25_model_td_17.npz\n",
      "ind=17 rank=25 time=2076.91s/519.76s acc=0.9740/0.9248/0.8409 f1=0.9742/0.9244/0.9049\n",
      "rankMZ=25_model_td_18.npz\n",
      "ind=18 rank=25 time=2079.28s/521.24s acc=0.9780/0.9258/0.8864 f1=0.9783/0.9263/0.9236\n",
      "rankMZ=25_model_td_19.npz\n",
      "ind=19 rank=25 time=2106.49s/482.58s acc=0.9809/0.9227/0.8864 f1=0.9810/0.9244/0.9337\n",
      "rankMZ=25_model_td_20.npz\n",
      "ind=20 rank=25 time=2061.91s/556.33s acc=0.9793/0.9287/0.8182 f1=0.9795/0.9305/0.8847\n",
      "rankMZ=25_model_td_21.npz\n",
      "ind=21 rank=25 time=2129.69s/516.70s acc=0.9767/0.9026/0.8182 f1=0.9768/0.9011/0.8483\n",
      "rankMZ=25_model_td_22.npz\n",
      "ind=22 rank=25 time=2084.06s/511.99s acc=0.9746/0.9558/0.8409 f1=0.9746/0.9564/0.9085\n",
      "rankMZ=25_model_td_23.npz\n",
      "ind=23 rank=25 time=2100.06s/503.19s acc=0.9763/0.9371/0.8182 f1=0.9762/0.9373/0.8475\n",
      "rankMZ=25_model_td_24.npz\n",
      "ind=24 rank=25 time=2091.97s/485.74s acc=0.9728/0.9368/0.8864 f1=0.9729/0.9381/0.9236\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset2)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "confusion_matrices = []\n",
    "\n",
    "predicted_pa_test = []\n",
    "predicted_pa_test2 = []\n",
    "\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r)\n",
    "    model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "    print model_filename\n",
    "    clf.loadParameters(model_dirname+model_filename)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_train_pred = clf.predict(X[train_indices[ind]])\n",
    "    toc = time.clock()\n",
    "    tms_loc = [toc-tic]\n",
    "    acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "    f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_test_pred, y_test_pred_explicit = clf.predict(X[test_indices[ind]], return_all=True)\n",
    "    toc = time.clock()\n",
    "    tms_loc.append(toc-tic)\n",
    "    conf_mat = confusion_matrix(y[test_indices[ind]], y_test_pred)\n",
    "    acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "    f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "    \n",
    "    y_test2_pred, y_test2_pred_explicit = clf.predict(X_test2, return_all=True)\n",
    "    acc_loc.append( accuracy_score(y_test2, y_test2_pred) )\n",
    "    f1_loc.append( f1_score(y_test2, y_test2_pred, average='weighted') )\n",
    "    \n",
    "    tms.append(tms_loc)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    \n",
    "    y_test_pred_explicit = y_test_pred_explicit.assign(TRUE=y[test_indices[ind]])\n",
    "    predicted_pa_test.append( y_test_pred_explicit.values )\n",
    "    y_test2_pred_explicit = y_test2_pred_explicit.assign(TRUE=y_test2)\n",
    "    predicted_pa_test2.append( y_test2_pred_explicit.values )\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rankMZ='+str(rank_mz)+model_filename_base+'+CCA',\n",
    "        tms=tms, confusion_matrices=confusion_matrices, accuracies=accuracies,\n",
    "        f1s=f1s, classes=clf.classes, predicted_pa_test=predicted_pa_test,\n",
    "        predicted_pa_test2=predicted_pa_test2\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs/%.2fs acc=%.4f/%.4f/%.4f f1=%.4f/%.4f/%.4f\" % (\n",
    "        ind, rank_mz, tms[-1][0], tms[-1][1], acc_loc[0], acc_loc[1], acc_loc[2],\n",
    "        f1_loc[0], f1_loc[1], f1_loc[2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample (from test) prediction time: 1.14 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.933628</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.976256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.933472</td>\n",
       "      <td>0.910985</td>\n",
       "      <td>0.976235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      test     test2     train\n",
       "0  accuracy  0.933628  0.863636  0.976256\n",
       "1        F1  0.933472  0.910985  0.976235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "rank = 25\n",
    "\n",
    "df = np.load( results_dirname+'rankMZ='+str(rank)+model_filename_base+'+CCA.npz' )\n",
    "\n",
    "\n",
    "accuracies = np.median(df['accuracies'], axis=0)\n",
    "f1s = np.median(df['f1s'], axis=0)\n",
    "tms = df['tms']\n",
    "\n",
    "numSampPerFold = map(lambda x: float(len(x)), test_indices)\n",
    "tms[:, 1] /= numSampPerFold\n",
    "\n",
    "tms = np.median(tms, axis=0)\n",
    "\n",
    "dataDict = {\n",
    "    'train': [accuracies[0], f1s[0]],\n",
    "    'test': [accuracies[1], f1s[1]],\n",
    "    'test2': [accuracies[2], f1s[2]],\n",
    "    'index': ['accuracy', 'F1']\n",
    "}\n",
    "\n",
    "print 'One sample (from test) prediction time: %.2f s' % (tms[1])\n",
    "\n",
    "table = pd.DataFrame(dataDict)\n",
    "table.set_index('index')\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: build models\n",
    "\n",
    "Grid search approach followed by inspection of accuracy (one times repeated K-fold)\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "n_splits = 5\n",
    "\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(n_splits):\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "        tic = time.clock()\n",
    "        clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "        toc = time.clock()\n",
    "        tms.append(toc-tic)\n",
    "        clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "        np.savez_compressed(\n",
    "            model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "            tms=tms\n",
    "        )\n",
    "        print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "            ind, rank_mz, tms[-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: inspect accuracy\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = ['cca', 'dcor']\n",
    "\n",
    "metric_name = metrics[0]\n",
    "\n",
    "if metric_name == 'cca':\n",
    "    metric = None\n",
    "elif metric_name == 'dcor':\n",
    "    metric = dcor.distance_correlation\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "n_splits = 5\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "for ind in xrange(n_splits):\n",
    "    tms_l = []\n",
    "    accuracies_l = []\n",
    "    f1s_l = []\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        \n",
    "        clf = TuckerClassifierLCMS(Nmz, r)\n",
    "        model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "        print model_filename\n",
    "        clf.loadParameters(model_dirname+model_filename)\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_train_pred = clf.predict(X[train_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc = [toc-tic]\n",
    "        acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "        f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_test_pred = clf.predict(X[test_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc.append(toc-tic)\n",
    "        acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "        f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "\n",
    "\n",
    "        tms_l.append(tms_loc)\n",
    "        accuracies_l.append(acc_loc)\n",
    "        f1s_l.append(f1_loc)\n",
    "    accuracies.append(accuracies_l)\n",
    "    f1s.append(f1s_l)\n",
    "    tms.append(tms_l)\n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rank_selection_metric='+metric_name+'_'+model_filename_prefix+'+'+metric_name,\n",
    "        tms=tms, accuracies=accuracies, f1s=f1s\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "tms = np.array(tms)\n",
    "\n",
    "print \"Accuracies:\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"F1-measures:\"\n",
    "print np.median(f1s, axis=0)\n",
    "print \"Prediction time (for all samples):\"\n",
    "print np.median(np.sum(tms, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look on components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_prefix = 'model_td_all'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "tic = time.clock()\n",
    "clf.fit(X, y, verbose=0)\n",
    "toc = time.clock()\n",
    "tms = toc-tic\n",
    "clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix)\n",
    "np.savez_compressed(\n",
    "    model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "    tms=tms\n",
    ")\n",
    "\n",
    "print 'Evaluation time: %.2f s' % (tms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankMZ=25_model_td_all.npz\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "eps = 10*np.spacing(1.)\n",
    "def func(i, A, B, Omega):\n",
    "    ii = int(i)\n",
    "    if (ii >= A.size) or (ii in Omega):\n",
    "        return +np.infty\n",
    "    rv = np.mean(np.abs(B[:, ii])) - np.log(eps+np.abs(A[ii]))\n",
    "    if np.isnan(rv):\n",
    "        return +np.infty\n",
    "    return rv\n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_all'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "rank = rank_mz, rank_pol\n",
    "n_comp = 3\n",
    "\n",
    "df = np.load(data_dirname + filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "clf = TuckerClassifierLCMS(Nmz, rank)\n",
    "model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+'.npz'\n",
    "print model_filename\n",
    "clf.loadParameters(model_dirname+model_filename)\n",
    "\n",
    "components = clf.MZspaces\n",
    "polspaces = clf.Polspaces_inv\n",
    "corrDict = {}\n",
    "#Z = X[test_indices[ind]].copy()\n",
    "# the first loop is for component spaces\n",
    "Omegas = {}\n",
    "for i_cl in xrange(len(clf.classes)):\n",
    "    tmp = []\n",
    "    current_component_class = clf.classes[i_cl]\n",
    "    # the second loop is for samples' classes\n",
    "    for j_cl in xrange(len(clf.classes)):\n",
    "        current_sample_class = clf.classes[j_cl]\n",
    "        which = np.where(y == current_sample_class)[0]\n",
    "        Z = np.einsum('ijk,kl->ijl', X[which], polspaces[current_component_class])\n",
    "        corrMat = np.corrcoef(Z.T[0], components[current_component_class], rowvar=False)\n",
    "        \n",
    "        corrMat += np.corrcoef(Z.T[1], components[current_component_class], rowvar=False)\n",
    "        corrMat *= 0.5\n",
    "        corrMat = corrMat[:len(which), len(which):]\n",
    "        \n",
    "        tmp.append( np.median(corrMat, axis=0) )\n",
    "    corrDict[current_component_class] = np.array(tmp)\n",
    "    spind = range(i_cl) + range(i_cl+1, len(clf.classes))\n",
    "    spind = tuple(spind)\n",
    "    Omega = []\n",
    "    f = lambda i: func(\n",
    "        i,\n",
    "        corrDict[current_component_class][i_cl, :],\n",
    "        corrDict[current_component_class][spind, :],\n",
    "        Omega\n",
    "    )\n",
    "    ranges = (slice(0, components[current_component_class].shape[1], 1),)\n",
    "    for l_c in xrange(n_comp):\n",
    "        p = scipy.optimize.brute(f, ranges)\n",
    "        p = int(p)\n",
    "        '''\n",
    "        print (\n",
    "            current_component_class,\n",
    "            corrDict[current_component_class][i_cl, p],\n",
    "            corrDict[current_component_class][:, p]\n",
    "        )\n",
    "        '''\n",
    "        Omega.append(p)\n",
    "    Omegas[current_component_class] = Omega\n",
    "\n",
    "np.savez_compressed(\n",
    "    model_dirname+'sntd_components', classes=clf.classes, components=components, Omegas=Omegas, \n",
    "    corrDict=corrDict\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
