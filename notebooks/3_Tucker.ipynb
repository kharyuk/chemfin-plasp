{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [1. Imports](#Imports)\n",
    "- [2. Train models with fixed rank for CV](#Train-models-with-fixed-rank-for-CV )\n",
    "- [3. Predict with learned models](#Predict-with-learned-models)\n",
    "- [4. Rank selection: build models](#Rank-selection:-build-models)\n",
    "- [5. Rank selection: inspect accuracy](#Rank-selection:-inspect-accuracy)\n",
    "\n",
    "[Back to Chemfin](../Chemfin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The first cell with code includes almost all necessary inputs.\n",
    "\n",
    "Required packages: [numpy](http://www.numpy.org/), [scikit-learn](http://scikit-learn.org/), [dcor](https://pypi.python.org/pypi/dcor).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from computational_utils import reshape\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tucker import estimateMzPolarityFactors\n",
    "from tucker import TuckerClassifierLCMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models with fixed rank for CV\n",
    "\n",
    "It is assumed that CV indices has been already precomputed with [Initialize](./1_Initialize.ipynb).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "    tic = time.clock()\n",
    "    clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "    toc = time.clock()\n",
    "    tms.append(toc-tic)\n",
    "    clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "    np.savez_compressed(\n",
    "        model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "        tms=tms\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "        ind, rank_mz, tms[-1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with learned models\n",
    "Principle angle used as measure of distance between two column-spaces.\n",
    "Requires additional imports of sklearn metrics.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "rank_mz = 25\n",
    "rank_pol = 2\n",
    "\n",
    "r = [rank_mz, rank_pol]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset2)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "confusion_matrices = []\n",
    "for ind in xrange(len(train_indices)):\n",
    "    clf = TuckerClassifierLCMS(Nmz, r)\n",
    "    model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "    print model_filename\n",
    "    clf.loadParameters(model_dirname+model_filename)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_train_pred = clf.predict(X[train_indices[ind]])\n",
    "    toc = time.clock()\n",
    "    tms_loc = [toc-tic]\n",
    "    acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "    f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "    \n",
    "    tic = time.clock()\n",
    "    y_test_pred = clf.predict(X[test_indices[ind]])\n",
    "    toc = time.clock()\n",
    "    tms_loc.append(toc-tic)\n",
    "    conf_mat = confusion_matrix(y[test_indices[ind]], y_test_pred)\n",
    "    acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "    f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "    \n",
    "    y_test2_pred = clf.predict(X_test2)\n",
    "    acc_loc.append( accuracy_score(y_test2, y_test2_pred) )\n",
    "    f1_loc.append( f1_score(y_test2, y_test2_pred, average='weighted') )\n",
    "    \n",
    "    tms.append(tms_loc)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rankMZ='+str(rank_mz)+model_filename_base+'+CCA',\n",
    "        tms=tms, confusion_matrices=confusion_matrices, accuracies=accuracies,\n",
    "        f1s=f1s, classes=clf.classes\n",
    "    )\n",
    "    print \"ind=%d rank=%d time=%.2fs/%.2fs acc=%.4f/%.4f/%.4f f1=%.4f/%.4f/%.4f\" % (\n",
    "        ind, rank_mz, tms[-1][0], tms[-1][1], acc_loc[0], acc_loc[1], acc_loc[2],\n",
    "        f1_loc[0], f1_loc[1], f1_loc[2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: build models\n",
    "\n",
    "Grid search approach followed by inspection of accuracy (one times repeated K-fold)\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_prefix = 'model_td'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "maxitnum = 1000\n",
    "n_splits = 5\n",
    "\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "for ind in xrange(n_splits):\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        clf = TuckerClassifierLCMS(Nmz, r, maxitnum=maxitnum)\n",
    "        tic = time.clock()\n",
    "        clf.fit(X[train_indices[ind]], y[train_indices[ind]], verbose=0)\n",
    "        toc = time.clock()\n",
    "        tms.append(toc-tic)\n",
    "        clf.saveParameters(model_dirname+'rankMZ='+str(rank_mz)+'_'+model_filename_prefix+'_'+str(ind))\n",
    "        np.savez_compressed(\n",
    "            model_dirname+'rankMZ='+str(rank_mz)+'_times_train_'+model_filename_prefix,\n",
    "            tms=tms\n",
    "        )\n",
    "        print \"ind=%d rank=%d time=%.2fs\" % (\n",
    "            ind, rank_mz, tms[-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank selection: inspect accuracy\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = ['cca', 'dcor']\n",
    "\n",
    "metric_name = metrics[0]\n",
    "\n",
    "if metric_name == 'cca':\n",
    "    metric = None\n",
    "elif metric_name == 'dcor':\n",
    "    metric = dcor.distance_correlation\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/tucker_decomposition/rank_selection/'\n",
    "model_filename_base = 'model_td_'\n",
    "results_dirname = '../results/'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_dataset2 = 'test2.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "n_splits = 5\n",
    "rank_mz_max = 25\n",
    "ranks_mz = np.arange(rank_mz_max) + 1\n",
    "rank_pol = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "X, y = df['data'], df['label']\n",
    "Nmz = X.shape[1]\n",
    "\n",
    "tms = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "for ind in xrange(n_splits):\n",
    "    tms_l = []\n",
    "    accuracies_l = []\n",
    "    f1s_l = []\n",
    "    for i in xrange(len(ranks_mz)):\n",
    "        rank_mz = ranks_mz[i]\n",
    "        r = [rank_mz, rank_pol]\n",
    "        \n",
    "        clf = TuckerClassifierLCMS(Nmz, r)\n",
    "        model_filename = 'rankMZ='+str(rank_mz)+'_'+model_filename_base+str(ind)+'.npz'\n",
    "        print model_filename\n",
    "        clf.loadParameters(model_dirname+model_filename)\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_train_pred = clf.predict(X[train_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc = [toc-tic]\n",
    "        acc_loc = [accuracy_score(y[train_indices[ind]], y_train_pred)]\n",
    "        f1_loc = [f1_score(y[train_indices[ind]], y_train_pred, average='weighted')]\n",
    "\n",
    "        tic = time.clock()\n",
    "        y_test_pred = clf.predict(X[test_indices[ind]], metric=metric)\n",
    "        toc = time.clock()\n",
    "        tms_loc.append(toc-tic)\n",
    "        acc_loc.append( accuracy_score(y[test_indices[ind]], y_test_pred) )\n",
    "        f1_loc.append( f1_score(y[test_indices[ind]], y_test_pred, average='weighted') )\n",
    "\n",
    "\n",
    "        tms_l.append(tms_loc)\n",
    "        accuracies_l.append(acc_loc)\n",
    "        f1s_l.append(f1_loc)\n",
    "    accuracies.append(accuracies_l)\n",
    "    f1s.append(f1s_l)\n",
    "    tms.append(tms_l)\n",
    "    np.savez_compressed(\n",
    "        results_dirname+'rank_selection_metric='+metric_name+'_'+model_filename_prefix+'+'+metric_name,\n",
    "        tms=tms, accuracies=accuracies, f1s=f1s\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "tms = np.array(tms)\n",
    "\n",
    "print \"Accuracies:\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"F1-measures:\"\n",
    "print np.median(f1s, axis=0)\n",
    "print \"Prediction time (for all samples):\"\n",
    "print np.median(np.sum(tms, axis=-1), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
