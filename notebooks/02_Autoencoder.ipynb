{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [1. Imports](#Imports)\n",
    "- [2. Build models](#Build-models)\n",
    "- [3. Approximation error](#Approximation-error)\n",
    "- [4. Encode data with computed autoencoders](#Encode-data-with-computed-autoencoders)\n",
    "- [5. Investigate how size of last encoding layer affects results: training models](#Investigate-how-size-of-last-encoding-layer-affects-results:-training-models)\n",
    "- [6. Investigate how size of last encoding layer affects results: encode data](#Investigate-how-size-of-last-encoding-layer-affects-results:-encode-data)\n",
    "- [7. Investigate how size of last encoding layer affects results: predict with logistic regression](#Investigate-how-size-of-last-encoding-layer-affects-results:-predict-with-logistic-regression)\n",
    "- [8. Logistic regression classifier with encoded data](#Logistic-regression-classifier-with-encoded-data)\n",
    "- [9. Gaussian Naive Bayes classifier with encoded data](#Gaussian-Naive-Bayes-classifier-with-encoded-data)\n",
    "- [10. Hybrid Bayesian classifier with bnlearn](#Hybrid-Bayesian-classifier-with-bnlearn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Back to Chemfin](../Chemfin.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "The first cell with code includes all necessary inputs.\n",
    "\n",
    "Requires [numpy](http://www.numpy.org/), [scikit-learn](http://scikit-learn.org/), [pyTorch](http://pytorch.org/), [Rpy2](https://rpy2.readthedocs.io).\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import autoencoder as ae\n",
    "\n",
    "random_state = 150\n",
    "torch.manual_seed(random_state);\n",
    "\n",
    "\n",
    "from computational_utils import reshape\n",
    "import bayesian_networks as bn\n",
    "\n",
    "from io_work import stringSplitByNumbers\n",
    "\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from computational_utils import reshape\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models\n",
    "\n",
    "Next cell contains script to build autoencoder models relevant to CV indexes supplied by data/cv_indices.npz.\n",
    "\n",
    "Parameters to control are:\n",
    "\n",
    "- sizes: list of integers which specifies output sizes for each encoding layer\n",
    "- batch_size: number of samples to be used for computing new update at each epoch\n",
    "- nEpoch: number of epochs for each layer\n",
    "- num_workers: number of parallel processes to work\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#truncated_features = True\n",
    "\n",
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/truncated/'\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "'''\n",
    "if truncated_features:\n",
    "    model_filename_prefix = 'model_ae_truncated_'\n",
    "\n",
    "    left_fraction = 30\n",
    "    geN = 20\n",
    "\n",
    "    data = bn.loadMatrix(data_dirname+filename_dataset, one_node=1, ignore_negative=0)\n",
    "    data, tau = bn.thresholdMatrix(data, left_fraction=left_fraction, one_node=1)\n",
    "    T, labels = data.iloc[:, 1:].values, data.iloc[:, 0].values\n",
    "    print 'truncated'\n",
    "else:\n",
    "'''\n",
    "model_filename_prefix = 'model_ae_'\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, labels = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize among samples\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "print 'full'\n",
    "    \n",
    "sizes = [400, 100, 25]\n",
    "nEpoch = [1000, 1000, 1000]\n",
    "batch_size = 200\n",
    "num_workers = 4\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "\n",
    "\n",
    "ae.buildAutoencoderModels(\n",
    "    T, train_indices, test_indices, sizes, model_dirname, nEpoch,\n",
    "    batch_size, num_workers, model_filename_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation error\n",
    "\n",
    "In this code data encoded and decoded with previously trained models. Resulting approximation (relative residual error by means of $l_2$ norm) is printed sample-wise.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/'\n",
    "model_filename_prefix = 'model_ae_'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, labels = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize among samples\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "N = T.shape[1]\n",
    "\n",
    "ae.checkRelRes(T, train_indices, test_indices, sizes, model_dirname, model_filename_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data with computed autoencoders\n",
    "\n",
    "It will produce data encoded with models from previous steps.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/'\n",
    "model_filename_prefix = 'model_aeGE20_'\n",
    "filename_dataset = 'dataset.npz'\n",
    "save_filename = 'autoencoded_' + filename_dataset\n",
    "filename_dataset2 = 'test2.npz'\n",
    "save_filename2 = 'autoencoded_' + filename_dataset2\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "num_workers = 12\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "ae.encodeDataset(df, sizes, model_dirname, model_filename_prefix,\n",
    "                  data_dirname+save_filename, num_workers, return_result=0)\n",
    "df = np.load(data_dirname+filename_dataset2)\n",
    "ae.encodeDataset(df, sizes, model_dirname, model_filename_prefix,\n",
    "                  data_dirname+save_filename2, num_workers, return_result=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate how size of last encoding layer affects results: training models\n",
    "\n",
    "Here we use only one repeat of 5-fold CV\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/last_layer/'\n",
    "model_filename_prefix = 'model_ae_'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "sizes_ll = range(1, sizes[-1]+1)\n",
    "nEpoch = [1000, 1000, 1000]\n",
    "batch_size = 200\n",
    "num_workers = 2\n",
    "n_splits = 5\n",
    "\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, labels = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize features of each sample\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "\n",
    "ae.investigateLastLayerTrain(T, train_indices[:n_splits], test_indices[:n_splits], sizes, sizes_ll,\n",
    "        model_dirname, nEpoch, batch_size, num_workers, model_filename_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying last layer size: approximation error\n",
    "\n",
    "In this code data encoded and decoded with previously trained models. Resulting approximation (relative residual error by means of  l1/l2  norm) is printed sample-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll=1_model_ae_0 [1600, 400, 100, 1]\n",
      "min=1.325e-01 / mean=4.935e-01 / median=4.816e-01 / max=1.007e+00\n",
      "min=1.334e-01 / mean=4.786e-01 / median=4.383e-01 / max=1.128e+00\n",
      "ll=1_model_ae_1 [1600, 400, 100, 1]\n",
      "min=1.736e-01 / mean=4.923e-01 / median=4.708e-01 / max=1.031e+00\n",
      "min=1.779e-01 / mean=5.162e-01 / median=5.038e-01 / max=1.094e+00\n",
      "ll=1_model_ae_2 [1600, 400, 100, 1]\n",
      "min=1.418e-01 / mean=4.868e-01 / median=4.682e-01 / max=1.023e+00\n",
      "min=1.396e-01 / mean=4.965e-01 / median=4.783e-01 / max=1.197e+00\n",
      "ll=1_model_ae_3 [1600, 400, 100, 1]\n",
      "min=1.398e-01 / mean=4.900e-01 / median=4.732e-01 / max=1.000e+00\n",
      "min=1.462e-01 / mean=5.134e-01 / median=5.013e-01 / max=1.198e+00\n",
      "ll=1_model_ae_4 [1600, 400, 100, 1]\n",
      "min=1.910e-01 / mean=5.042e-01 / median=4.839e-01 / max=1.087e+00\n",
      "min=1.919e-01 / mean=5.086e-01 / median=4.889e-01 / max=9.895e-01\n",
      "ll=2_model_ae_0 [1600, 400, 100, 2]\n",
      "min=1.179e-01 / mean=3.847e-01 / median=3.711e-01 / max=8.650e-01\n",
      "min=1.325e-01 / mean=4.013e-01 / median=3.748e-01 / max=1.212e+00\n",
      "ll=2_model_ae_1 [1600, 400, 100, 2]\n",
      "min=1.222e-01 / mean=3.908e-01 / median=3.733e-01 / max=8.533e-01\n",
      "min=1.277e-01 / mean=4.277e-01 / median=4.035e-01 / max=1.159e+00\n",
      "ll=2_model_ae_2 [1600, 400, 100, 2]\n",
      "min=1.298e-01 / mean=4.017e-01 / median=3.875e-01 / max=9.652e-01\n",
      "min=1.271e-01 / mean=4.276e-01 / median=4.039e-01 / max=1.020e+00\n",
      "ll=2_model_ae_3 [1600, 400, 100, 2]\n",
      "min=1.124e-01 / mean=3.759e-01 / median=3.578e-01 / max=1.071e+00\n",
      "min=1.165e-01 / mean=4.102e-01 / median=3.941e-01 / max=1.080e+00\n",
      "ll=2_model_ae_4 [1600, 400, 100, 2]\n",
      "min=1.181e-01 / mean=3.833e-01 / median=3.684e-01 / max=1.049e+00\n",
      "min=1.197e-01 / mean=4.025e-01 / median=3.902e-01 / max=1.075e+00\n",
      "ll=3_model_ae_0 [1600, 400, 100, 3]\n",
      "min=1.019e-01 / mean=3.019e-01 / median=2.888e-01 / max=8.061e-01\n",
      "min=1.087e-01 / mean=3.379e-01 / median=3.131e-01 / max=1.178e+00\n",
      "ll=3_model_ae_1 [1600, 400, 100, 3]\n",
      "min=9.353e-02 / mean=3.109e-01 / median=2.910e-01 / max=7.649e-01\n",
      "min=1.008e-01 / mean=3.569e-01 / median=3.291e-01 / max=1.183e+00\n",
      "ll=3_model_ae_2 [1600, 400, 100, 3]\n",
      "min=1.061e-01 / mean=3.170e-01 / median=3.014e-01 / max=8.053e-01\n",
      "min=1.008e-01 / mean=3.497e-01 / median=3.219e-01 / max=8.837e-01\n",
      "ll=3_model_ae_3 [1600, 400, 100, 3]\n",
      "min=1.050e-01 / mean=2.988e-01 / median=2.801e-01 / max=7.927e-01\n",
      "min=1.128e-01 / mean=3.535e-01 / median=3.194e-01 / max=9.817e-01\n",
      "ll=3_model_ae_4 [1600, 400, 100, 3]\n",
      "min=9.306e-02 / mean=2.978e-01 / median=2.818e-01 / max=7.567e-01\n",
      "min=1.085e-01 / mean=3.343e-01 / median=3.156e-01 / max=1.107e+00\n",
      "ll=4_model_ae_0 [1600, 400, 100, 4]\n",
      "min=9.338e-02 / mean=2.604e-01 / median=2.470e-01 / max=7.414e-01\n",
      "min=1.002e-01 / mean=3.051e-01 / median=2.811e-01 / max=1.143e+00\n",
      "ll=4_model_ae_1 [1600, 400, 100, 4]\n",
      "min=8.329e-02 / mean=2.656e-01 / median=2.504e-01 / max=7.186e-01\n",
      "min=1.027e-01 / mean=3.150e-01 / median=2.844e-01 / max=1.021e+00\n",
      "ll=4_model_ae_2 [1600, 400, 100, 4]\n",
      "min=9.634e-02 / mean=2.688e-01 / median=2.529e-01 / max=7.949e-01\n",
      "min=9.270e-02 / mean=3.130e-01 / median=2.816e-01 / max=9.051e-01\n",
      "ll=4_model_ae_3 [1600, 400, 100, 4]\n",
      "min=7.692e-02 / mean=2.556e-01 / median=2.381e-01 / max=7.108e-01\n",
      "min=9.578e-02 / mean=3.069e-01 / median=2.776e-01 / max=8.650e-01\n",
      "ll=4_model_ae_4 [1600, 400, 100, 4]\n",
      "min=8.117e-02 / mean=2.512e-01 / median=2.364e-01 / max=6.998e-01\n",
      "min=9.707e-02 / mean=2.991e-01 / median=2.682e-01 / max=1.108e+00\n",
      "ll=5_model_ae_0 [1600, 400, 100, 5]\n",
      "min=7.891e-02 / mean=2.333e-01 / median=2.179e-01 / max=6.411e-01\n",
      "min=8.989e-02 / mean=2.751e-01 / median=2.478e-01 / max=9.736e-01\n",
      "ll=5_model_ae_1 [1600, 400, 100, 5]\n",
      "min=9.288e-02 / mean=2.501e-01 / median=2.342e-01 / max=6.805e-01\n",
      "min=1.016e-01 / mean=2.995e-01 / median=2.701e-01 / max=1.166e+00\n",
      "ll=5_model_ae_2 [1600, 400, 100, 5]\n",
      "min=8.332e-02 / mean=2.504e-01 / median=2.329e-01 / max=7.208e-01\n",
      "min=8.707e-02 / mean=2.932e-01 / median=2.601e-01 / max=1.044e+00\n",
      "ll=5_model_ae_3 [1600, 400, 100, 5]\n",
      "min=8.278e-02 / mean=2.461e-01 / median=2.300e-01 / max=6.931e-01\n",
      "min=9.557e-02 / mean=2.938e-01 / median=2.730e-01 / max=9.523e-01\n",
      "ll=5_model_ae_4 [1600, 400, 100, 5]\n",
      "min=7.124e-02 / mean=2.399e-01 / median=2.222e-01 / max=6.806e-01\n",
      "min=9.705e-02 / mean=2.883e-01 / median=2.595e-01 / max=1.289e+00\n",
      "ll=6_model_ae_0 [1600, 400, 100, 6]\n",
      "min=7.088e-02 / mean=2.162e-01 / median=2.036e-01 / max=5.859e-01\n",
      "min=7.971e-02 / mean=2.565e-01 / median=2.310e-01 / max=1.217e+00\n",
      "ll=6_model_ae_1 [1600, 400, 100, 6]\n",
      "min=8.393e-02 / mean=2.245e-01 / median=2.114e-01 / max=8.294e-01\n",
      "min=8.151e-02 / mean=2.738e-01 / median=2.424e-01 / max=8.512e-01\n",
      "ll=6_model_ae_2 [1600, 400, 100, 6]\n",
      "min=8.067e-02 / mean=2.228e-01 / median=2.111e-01 / max=5.954e-01\n",
      "min=8.290e-02 / mean=2.608e-01 / median=2.426e-01 / max=9.823e-01\n",
      "ll=6_model_ae_3 [1600, 400, 100, 6]\n",
      "min=8.102e-02 / mean=2.226e-01 / median=2.071e-01 / max=7.217e-01\n",
      "min=9.012e-02 / mean=2.835e-01 / median=2.509e-01 / max=1.111e+00\n",
      "ll=6_model_ae_4 [1600, 400, 100, 6]\n",
      "min=6.984e-02 / mean=2.214e-01 / median=2.061e-01 / max=7.125e-01\n",
      "min=9.113e-02 / mean=2.622e-01 / median=2.376e-01 / max=9.132e-01\n",
      "ll=7_model_ae_0 [1600, 400, 100, 7]\n",
      "min=7.401e-02 / mean=2.052e-01 / median=1.923e-01 / max=6.072e-01\n",
      "min=7.806e-02 / mean=2.428e-01 / median=2.235e-01 / max=1.014e+00\n",
      "ll=7_model_ae_1 [1600, 400, 100, 7]\n",
      "min=8.355e-02 / mean=2.160e-01 / median=2.052e-01 / max=6.296e-01\n",
      "min=9.256e-02 / mean=2.652e-01 / median=2.369e-01 / max=7.642e-01\n",
      "ll=7_model_ae_2 [1600, 400, 100, 7]\n",
      "min=7.759e-02 / mean=2.044e-01 / median=1.913e-01 / max=5.761e-01\n",
      "min=8.258e-02 / mean=2.439e-01 / median=2.177e-01 / max=8.147e-01\n",
      "ll=7_model_ae_3 [1600, 400, 100, 7]\n",
      "min=7.692e-02 / mean=2.123e-01 / median=1.971e-01 / max=6.581e-01\n",
      "min=8.829e-02 / mean=2.659e-01 / median=2.369e-01 / max=1.074e+00\n",
      "ll=7_model_ae_4 [1600, 400, 100, 7]\n",
      "min=7.311e-02 / mean=2.086e-01 / median=1.977e-01 / max=6.125e-01\n",
      "min=7.739e-02 / mean=2.489e-01 / median=2.266e-01 / max=9.092e-01\n",
      "ll=8_model_ae_0 [1600, 400, 100, 8]\n",
      "min=6.382e-02 / mean=1.878e-01 / median=1.771e-01 / max=5.895e-01\n",
      "min=6.941e-02 / mean=2.291e-01 / median=2.043e-01 / max=1.035e+00\n",
      "ll=8_model_ae_1 [1600, 400, 100, 8]\n",
      "min=7.679e-02 / mean=1.971e-01 / median=1.884e-01 / max=6.605e-01\n",
      "min=7.687e-02 / mean=2.435e-01 / median=2.142e-01 / max=9.322e-01\n",
      "ll=8_model_ae_2 [1600, 400, 100, 8]\n",
      "min=7.539e-02 / mean=2.037e-01 / median=1.899e-01 / max=6.841e-01\n",
      "min=8.380e-02 / mean=2.469e-01 / median=2.205e-01 / max=1.041e+00\n",
      "ll=8_model_ae_3 [1600, 400, 100, 8]\n",
      "min=7.170e-02 / mean=1.974e-01 / median=1.838e-01 / max=6.274e-01\n",
      "min=8.073e-02 / mean=2.464e-01 / median=2.205e-01 / max=9.089e-01\n",
      "ll=8_model_ae_4 [1600, 400, 100, 8]\n",
      "min=7.415e-02 / mean=1.875e-01 / median=1.782e-01 / max=6.366e-01\n",
      "min=8.557e-02 / mean=2.328e-01 / median=2.083e-01 / max=8.722e-01\n",
      "ll=9_model_ae_0 [1600, 400, 100, 9]\n",
      "min=6.616e-02 / mean=1.749e-01 / median=1.645e-01 / max=5.198e-01\n",
      "min=7.034e-02 / mean=2.166e-01 / median=1.965e-01 / max=8.426e-01\n",
      "ll=9_model_ae_1 [1600, 400, 100, 9]\n",
      "min=7.755e-02 / mean=1.848e-01 / median=1.762e-01 / max=5.978e-01\n",
      "min=9.193e-02 / mean=2.379e-01 / median=2.038e-01 / max=1.206e+00\n",
      "ll=9_model_ae_2 [1600, 400, 100, 9]\n",
      "min=6.988e-02 / mean=1.799e-01 / median=1.709e-01 / max=5.193e-01\n",
      "min=7.771e-02 / mean=2.222e-01 / median=1.975e-01 / max=8.954e-01\n",
      "ll=9_model_ae_3 [1600, 400, 100, 9]\n",
      "min=7.742e-02 / mean=1.825e-01 / median=1.714e-01 / max=6.206e-01\n",
      "min=8.189e-02 / mean=2.338e-01 / median=2.068e-01 / max=8.933e-01\n",
      "ll=9_model_ae_4 [1600, 400, 100, 9]\n",
      "min=8.286e-02 / mean=1.871e-01 / median=1.803e-01 / max=6.187e-01\n",
      "min=8.786e-02 / mean=2.278e-01 / median=2.044e-01 / max=7.088e-01\n",
      "ll=10_model_ae_0 [1600, 400, 100, 10]\n",
      "min=7.834e-02 / mean=1.733e-01 / median=1.647e-01 / max=5.884e-01\n",
      "min=7.769e-02 / mean=2.153e-01 / median=1.912e-01 / max=9.784e-01\n",
      "ll=10_model_ae_1 [1600, 400, 100, 10]\n",
      "min=7.823e-02 / mean=1.805e-01 / median=1.708e-01 / max=5.576e-01\n",
      "min=8.694e-02 / mean=2.284e-01 / median=1.992e-01 / max=7.838e-01\n",
      "ll=10_model_ae_2 [1600, 400, 100, 10]\n",
      "min=6.378e-02 / mean=1.771e-01 / median=1.689e-01 / max=5.503e-01\n",
      "min=7.462e-02 / mean=2.156e-01 / median=1.911e-01 / max=8.540e-01\n",
      "ll=10_model_ae_3 [1600, 400, 100, 10]\n",
      "min=7.260e-02 / mean=1.709e-01 / median=1.610e-01 / max=5.763e-01\n",
      "min=7.151e-02 / mean=2.210e-01 / median=1.968e-01 / max=6.782e-01\n",
      "ll=10_model_ae_4 [1600, 400, 100, 10]\n",
      "min=6.458e-02 / mean=1.715e-01 / median=1.633e-01 / max=5.256e-01\n",
      "min=7.864e-02 / mean=2.135e-01 / median=1.931e-01 / max=7.800e-01\n",
      "ll=11_model_ae_0 [1600, 400, 100, 11]\n",
      "min=6.550e-02 / mean=1.584e-01 / median=1.517e-01 / max=4.219e-01\n",
      "min=7.095e-02 / mean=2.015e-01 / median=1.777e-01 / max=8.289e-01\n",
      "ll=11_model_ae_1 [1600, 400, 100, 11]\n",
      "min=6.631e-02 / mean=1.666e-01 / median=1.584e-01 / max=5.595e-01\n",
      "min=6.785e-02 / mean=2.155e-01 / median=1.823e-01 / max=7.038e-01\n",
      "ll=11_model_ae_2 [1600, 400, 100, 11]\n",
      "min=6.611e-02 / mean=1.654e-01 / median=1.574e-01 / max=5.200e-01\n",
      "min=6.971e-02 / mean=2.055e-01 / median=1.799e-01 / max=1.065e+00\n",
      "ll=11_model_ae_3 [1600, 400, 100, 11]\n",
      "min=7.196e-02 / mean=1.634e-01 / median=1.557e-01 / max=5.341e-01\n",
      "min=7.950e-02 / mean=2.115e-01 / median=1.916e-01 / max=8.286e-01\n",
      "ll=11_model_ae_4 [1600, 400, 100, 11]\n",
      "min=6.747e-02 / mean=1.635e-01 / median=1.552e-01 / max=5.611e-01\n",
      "min=7.160e-02 / mean=2.074e-01 / median=1.850e-01 / max=7.033e-01\n",
      "ll=12_model_ae_0 [1600, 400, 100, 12]\n",
      "min=6.552e-02 / mean=1.534e-01 / median=1.466e-01 / max=5.963e-01\n",
      "min=6.641e-02 / mean=1.974e-01 / median=1.721e-01 / max=9.124e-01\n",
      "ll=12_model_ae_1 [1600, 400, 100, 12]\n",
      "min=6.992e-02 / mean=1.588e-01 / median=1.506e-01 / max=5.510e-01\n",
      "min=6.523e-02 / mean=2.080e-01 / median=1.786e-01 / max=7.266e-01\n",
      "ll=12_model_ae_2 [1600, 400, 100, 12]\n",
      "min=6.579e-02 / mean=1.565e-01 / median=1.489e-01 / max=5.149e-01\n",
      "min=6.924e-02 / mean=1.964e-01 / median=1.711e-01 / max=9.516e-01\n",
      "ll=12_model_ae_3 [1600, 400, 100, 12]\n",
      "min=6.680e-02 / mean=1.582e-01 / median=1.509e-01 / max=5.085e-01\n",
      "min=7.076e-02 / mean=2.112e-01 / median=1.817e-01 / max=9.128e-01\n",
      "ll=12_model_ae_4 [1600, 400, 100, 12]\n",
      "min=6.593e-02 / mean=1.535e-01 / median=1.461e-01 / max=5.790e-01\n",
      "min=7.305e-02 / mean=1.989e-01 / median=1.735e-01 / max=6.817e-01\n",
      "ll=13_model_ae_0 [1600, 400, 100, 13]\n",
      "min=6.357e-02 / mean=1.446e-01 / median=1.383e-01 / max=4.162e-01\n",
      "min=6.391e-02 / mean=1.893e-01 / median=1.650e-01 / max=7.911e-01\n",
      "ll=13_model_ae_1 [1600, 400, 100, 13]\n",
      "min=6.316e-02 / mean=1.591e-01 / median=1.536e-01 / max=5.454e-01\n",
      "min=6.038e-02 / mean=2.075e-01 / median=1.797e-01 / max=7.229e-01\n",
      "ll=13_model_ae_2 [1600, 400, 100, 13]\n",
      "min=6.756e-02 / mean=1.535e-01 / median=1.466e-01 / max=5.254e-01\n",
      "min=7.596e-02 / mean=1.946e-01 / median=1.730e-01 / max=8.309e-01\n",
      "ll=13_model_ae_3 [1600, 400, 100, 13]\n",
      "min=6.887e-02 / mean=1.485e-01 / median=1.439e-01 / max=4.128e-01\n",
      "min=7.540e-02 / mean=1.986e-01 / median=1.755e-01 / max=6.524e-01\n",
      "ll=13_model_ae_4 [1600, 400, 100, 13]\n",
      "min=6.096e-02 / mean=1.513e-01 / median=1.467e-01 / max=4.448e-01\n",
      "min=7.481e-02 / mean=1.932e-01 / median=1.738e-01 / max=6.710e-01\n",
      "ll=14_model_ae_0 [1600, 400, 100, 14]\n",
      "min=5.190e-02 / mean=1.438e-01 / median=1.387e-01 / max=4.018e-01\n",
      "min=6.428e-02 / mean=1.879e-01 / median=1.668e-01 / max=9.184e-01\n",
      "ll=14_model_ae_1 [1600, 400, 100, 14]\n",
      "min=6.710e-02 / mean=1.411e-01 / median=1.363e-01 / max=3.950e-01\n",
      "min=6.491e-02 / mean=1.919e-01 / median=1.573e-01 / max=8.822e-01\n",
      "ll=14_model_ae_2 [1600, 400, 100, 14]\n",
      "min=7.009e-02 / mean=1.542e-01 / median=1.474e-01 / max=4.999e-01\n",
      "min=7.079e-02 / mean=1.923e-01 / median=1.695e-01 / max=9.411e-01\n",
      "ll=14_model_ae_3 [1600, 400, 100, 14]\n",
      "min=6.411e-02 / mean=1.504e-01 / median=1.444e-01 / max=5.094e-01\n",
      "min=7.829e-02 / mean=2.007e-01 / median=1.741e-01 / max=7.067e-01\n",
      "ll=14_model_ae_4 [1600, 400, 100, 14]\n",
      "min=5.984e-02 / mean=1.464e-01 / median=1.412e-01 / max=5.182e-01\n",
      "min=6.416e-02 / mean=1.910e-01 / median=1.659e-01 / max=8.415e-01\n",
      "ll=15_model_ae_0 [1600, 400, 100, 15]\n",
      "min=5.233e-02 / mean=1.358e-01 / median=1.298e-01 / max=3.985e-01\n",
      "min=6.744e-02 / mean=1.831e-01 / median=1.574e-01 / max=8.974e-01\n",
      "ll=15_model_ae_1 [1600, 400, 100, 15]\n",
      "min=5.845e-02 / mean=1.418e-01 / median=1.371e-01 / max=3.861e-01\n",
      "min=5.964e-02 / mean=1.882e-01 / median=1.584e-01 / max=8.366e-01\n",
      "ll=15_model_ae_2 [1600, 400, 100, 15]\n",
      "min=7.515e-02 / mean=1.499e-01 / median=1.430e-01 / max=4.628e-01\n",
      "min=7.627e-02 / mean=1.907e-01 / median=1.683e-01 / max=9.986e-01\n",
      "ll=15_model_ae_3 [1600, 400, 100, 15]\n",
      "min=6.872e-02 / mean=1.407e-01 / median=1.351e-01 / max=3.962e-01\n",
      "min=7.253e-02 / mean=1.906e-01 / median=1.685e-01 / max=7.649e-01\n",
      "ll=15_model_ae_4 [1600, 400, 100, 15]\n",
      "min=7.432e-02 / mean=1.479e-01 / median=1.427e-01 / max=4.147e-01\n",
      "min=7.191e-02 / mean=1.900e-01 / median=1.661e-01 / max=6.677e-01\n",
      "ll=16_model_ae_0 [1600, 400, 100, 16]\n",
      "min=5.801e-02 / mean=1.336e-01 / median=1.278e-01 / max=3.657e-01\n",
      "min=6.725e-02 / mean=1.807e-01 / median=1.570e-01 / max=8.467e-01\n",
      "ll=16_model_ae_1 [1600, 400, 100, 16]\n",
      "min=6.090e-02 / mean=1.443e-01 / median=1.405e-01 / max=3.909e-01\n",
      "min=6.743e-02 / mean=1.950e-01 / median=1.663e-01 / max=8.104e-01\n",
      "ll=16_model_ae_2 [1600, 400, 100, 16]\n",
      "min=7.508e-02 / mean=1.472e-01 / median=1.415e-01 / max=4.860e-01\n",
      "min=7.387e-02 / mean=1.861e-01 / median=1.612e-01 / max=8.382e-01\n",
      "ll=16_model_ae_3 [1600, 400, 100, 16]\n",
      "min=6.267e-02 / mean=1.434e-01 / median=1.358e-01 / max=5.702e-01\n",
      "min=6.707e-02 / mean=1.924e-01 / median=1.697e-01 / max=6.427e-01\n",
      "ll=16_model_ae_4 [1600, 400, 100, 16]\n",
      "min=6.264e-02 / mean=1.369e-01 / median=1.317e-01 / max=3.997e-01\n",
      "min=6.181e-02 / mean=1.818e-01 / median=1.555e-01 / max=6.761e-01\n",
      "ll=17_model_ae_0 [1600, 400, 100, 17]\n",
      "min=6.594e-02 / mean=1.288e-01 / median=1.238e-01 / max=3.864e-01\n",
      "min=6.713e-02 / mean=1.720e-01 / median=1.487e-01 / max=8.216e-01\n",
      "ll=17_model_ae_1 [1600, 400, 100, 17]\n",
      "min=5.959e-02 / mean=1.338e-01 / median=1.285e-01 / max=3.333e-01\n",
      "min=7.145e-02 / mean=1.832e-01 / median=1.519e-01 / max=7.775e-01\n",
      "ll=17_model_ae_2 [1600, 400, 100, 17]\n",
      "min=6.045e-02 / mean=1.363e-01 / median=1.313e-01 / max=3.732e-01\n",
      "min=6.340e-02 / mean=1.746e-01 / median=1.525e-01 / max=8.657e-01\n",
      "ll=17_model_ae_3 [1600, 400, 100, 17]\n",
      "min=6.501e-02 / mean=1.322e-01 / median=1.263e-01 / max=3.759e-01\n",
      "min=6.799e-02 / mean=1.787e-01 / median=1.576e-01 / max=6.287e-01\n",
      "ll=17_model_ae_4 [1600, 400, 100, 17]\n",
      "min=5.728e-02 / mean=1.336e-01 / median=1.288e-01 / max=3.960e-01\n",
      "min=6.999e-02 / mean=1.779e-01 / median=1.549e-01 / max=6.256e-01\n",
      "ll=18_model_ae_0 [1600, 400, 100, 18]\n",
      "min=5.671e-02 / mean=1.306e-01 / median=1.249e-01 / max=3.512e-01\n",
      "min=6.678e-02 / mean=1.723e-01 / median=1.485e-01 / max=9.914e-01\n",
      "ll=18_model_ae_1 [1600, 400, 100, 18]\n",
      "min=6.670e-02 / mean=1.356e-01 / median=1.321e-01 / max=3.937e-01\n",
      "min=7.213e-02 / mean=1.854e-01 / median=1.581e-01 / max=7.788e-01\n",
      "ll=18_model_ae_2 [1600, 400, 100, 18]\n",
      "min=6.779e-02 / mean=1.385e-01 / median=1.337e-01 / max=3.803e-01\n",
      "min=7.232e-02 / mean=1.775e-01 / median=1.554e-01 / max=9.165e-01\n",
      "ll=18_model_ae_3 [1600, 400, 100, 18]\n",
      "min=5.628e-02 / mean=1.364e-01 / median=1.331e-01 / max=3.813e-01\n",
      "min=6.490e-02 / mean=1.816e-01 / median=1.636e-01 / max=6.014e-01\n",
      "ll=18_model_ae_4 [1600, 400, 100, 18]\n",
      "min=5.698e-02 / mean=1.282e-01 / median=1.229e-01 / max=4.297e-01\n",
      "min=6.767e-02 / mean=1.726e-01 / median=1.496e-01 / max=5.675e-01\n",
      "ll=19_model_ae_0 [1600, 400, 100, 19]\n",
      "min=5.406e-02 / mean=1.216e-01 / median=1.166e-01 / max=3.501e-01\n",
      "min=6.181e-02 / mean=1.680e-01 / median=1.462e-01 / max=8.399e-01\n",
      "ll=19_model_ae_1 [1600, 400, 100, 19]\n",
      "min=5.342e-02 / mean=1.265e-01 / median=1.221e-01 / max=3.225e-01\n",
      "min=5.575e-02 / mean=1.771e-01 / median=1.478e-01 / max=7.991e-01\n",
      "ll=19_model_ae_2 [1600, 400, 100, 19]\n",
      "min=6.066e-02 / mean=1.348e-01 / median=1.307e-01 / max=4.438e-01\n",
      "min=6.754e-02 / mean=1.727e-01 / median=1.504e-01 / max=8.676e-01\n",
      "ll=19_model_ae_3 [1600, 400, 100, 19]\n",
      "min=6.021e-02 / mean=1.303e-01 / median=1.267e-01 / max=3.468e-01\n",
      "min=6.379e-02 / mean=1.775e-01 / median=1.558e-01 / max=6.222e-01\n",
      "ll=19_model_ae_4 [1600, 400, 100, 19]\n",
      "min=5.932e-02 / mean=1.289e-01 / median=1.239e-01 / max=5.179e-01\n",
      "min=6.845e-02 / mean=1.707e-01 / median=1.473e-01 / max=6.233e-01\n",
      "ll=20_model_ae_0 [1600, 400, 100, 20]\n",
      "min=5.518e-02 / mean=1.228e-01 / median=1.172e-01 / max=3.516e-01\n",
      "min=5.419e-02 / mean=1.681e-01 / median=1.431e-01 / max=1.111e+00\n",
      "ll=20_model_ae_1 [1600, 400, 100, 20]\n",
      "min=5.308e-02 / mean=1.262e-01 / median=1.211e-01 / max=3.257e-01\n",
      "min=5.674e-02 / mean=1.753e-01 / median=1.427e-01 / max=6.971e-01\n",
      "ll=20_model_ae_2 [1600, 400, 100, 20]\n",
      "min=6.624e-02 / mean=1.262e-01 / median=1.219e-01 / max=3.010e-01\n",
      "min=7.020e-02 / mean=1.676e-01 / median=1.432e-01 / max=9.542e-01\n",
      "ll=20_model_ae_3 [1600, 400, 100, 20]\n",
      "min=6.445e-02 / mean=1.282e-01 / median=1.244e-01 / max=2.836e-01\n",
      "min=6.979e-02 / mean=1.756e-01 / median=1.526e-01 / max=6.215e-01\n",
      "ll=20_model_ae_4 [1600, 400, 100, 20]\n",
      "min=5.506e-02 / mean=1.266e-01 / median=1.223e-01 / max=3.283e-01\n",
      "min=6.440e-02 / mean=1.719e-01 / median=1.505e-01 / max=6.329e-01\n",
      "ll=21_model_ae_0 [1600, 400, 100, 21]\n",
      "min=5.229e-02 / mean=1.197e-01 / median=1.152e-01 / max=3.681e-01\n",
      "min=6.333e-02 / mean=1.647e-01 / median=1.425e-01 / max=6.992e-01\n",
      "ll=21_model_ae_1 [1600, 400, 100, 21]\n",
      "min=5.224e-02 / mean=1.218e-01 / median=1.184e-01 / max=2.921e-01\n",
      "min=5.751e-02 / mean=1.716e-01 / median=1.408e-01 / max=9.611e-01\n",
      "ll=21_model_ae_2 [1600, 400, 100, 21]\n",
      "min=6.772e-02 / mean=1.310e-01 / median=1.260e-01 / max=3.113e-01\n",
      "min=7.209e-02 / mean=1.696e-01 / median=1.472e-01 / max=7.482e-01\n",
      "ll=21_model_ae_3 [1600, 400, 100, 21]\n",
      "min=6.033e-02 / mean=1.280e-01 / median=1.231e-01 / max=3.785e-01\n",
      "min=6.995e-02 / mean=1.752e-01 / median=1.544e-01 / max=5.616e-01\n",
      "ll=21_model_ae_4 [1600, 400, 100, 21]\n",
      "min=6.352e-02 / mean=1.271e-01 / median=1.230e-01 / max=5.200e-01\n",
      "min=7.091e-02 / mean=1.717e-01 / median=1.466e-01 / max=7.044e-01\n",
      "ll=22_model_ae_0 [1600, 400, 100, 22]\n",
      "min=5.799e-02 / mean=1.190e-01 / median=1.151e-01 / max=3.203e-01\n",
      "min=5.991e-02 / mean=1.649e-01 / median=1.398e-01 / max=7.700e-01\n",
      "ll=22_model_ae_1 [1600, 400, 100, 22]\n",
      "min=5.404e-02 / mean=1.202e-01 / median=1.165e-01 / max=3.430e-01\n",
      "min=6.465e-02 / mean=1.720e-01 / median=1.402e-01 / max=9.218e-01\n",
      "ll=22_model_ae_2 [1600, 400, 100, 22]\n",
      "min=5.548e-02 / mean=1.251e-01 / median=1.209e-01 / max=4.484e-01\n",
      "min=6.099e-02 / mean=1.652e-01 / median=1.424e-01 / max=8.278e-01\n",
      "ll=22_model_ae_3 [1600, 400, 100, 22]\n",
      "min=6.359e-02 / mean=1.240e-01 / median=1.201e-01 / max=3.655e-01\n",
      "min=7.446e-02 / mean=1.716e-01 / median=1.507e-01 / max=5.042e-01\n",
      "ll=22_model_ae_4 [1600, 400, 100, 22]\n",
      "min=6.647e-02 / mean=1.289e-01 / median=1.252e-01 / max=3.837e-01\n",
      "min=6.961e-02 / mean=1.725e-01 / median=1.489e-01 / max=5.725e-01\n",
      "ll=23_model_ae_0 [1600, 400, 100, 23]\n",
      "min=4.917e-02 / mean=1.140e-01 / median=1.103e-01 / max=4.223e-01\n",
      "min=5.810e-02 / mean=1.598e-01 / median=1.372e-01 / max=7.183e-01\n",
      "ll=23_model_ae_1 [1600, 400, 100, 23]\n",
      "min=5.590e-02 / mean=1.232e-01 / median=1.205e-01 / max=3.111e-01\n",
      "min=5.902e-02 / mean=1.704e-01 / median=1.437e-01 / max=7.822e-01\n",
      "ll=23_model_ae_2 [1600, 400, 100, 23]\n",
      "min=5.175e-02 / mean=1.194e-01 / median=1.148e-01 / max=3.277e-01\n",
      "min=5.493e-02 / mean=1.617e-01 / median=1.391e-01 / max=9.284e-01\n",
      "ll=23_model_ae_3 [1600, 400, 100, 23]\n",
      "min=6.078e-02 / mean=1.279e-01 / median=1.244e-01 / max=2.935e-01\n",
      "min=6.181e-02 / mean=1.709e-01 / median=1.471e-01 / max=5.964e-01\n",
      "ll=23_model_ae_4 [1600, 400, 100, 23]\n",
      "min=6.117e-02 / mean=1.277e-01 / median=1.239e-01 / max=3.021e-01\n",
      "min=6.707e-02 / mean=1.707e-01 / median=1.487e-01 / max=5.056e-01\n",
      "ll=24_model_ae_0 [1600, 400, 100, 24]\n",
      "min=5.213e-02 / mean=1.124e-01 / median=1.082e-01 / max=3.345e-01\n",
      "min=5.552e-02 / mean=1.593e-01 / median=1.342e-01 / max=7.074e-01\n",
      "ll=24_model_ae_1 [1600, 400, 100, 24]\n",
      "min=5.609e-02 / mean=1.196e-01 / median=1.157e-01 / max=2.966e-01\n",
      "min=5.741e-02 / mean=1.710e-01 / median=1.402e-01 / max=7.573e-01\n",
      "ll=24_model_ae_2 [1600, 400, 100, 24]\n",
      "min=6.948e-02 / mean=1.463e-01 / median=1.424e-01 / max=3.023e-01\n",
      "min=7.750e-02 / mean=1.820e-01 / median=1.579e-01 / max=8.473e-01\n",
      "ll=24_model_ae_3 [1600, 400, 100, 24]\n",
      "min=6.470e-02 / mean=1.211e-01 / median=1.189e-01 / max=3.390e-01\n",
      "min=6.947e-02 / mean=1.678e-01 / median=1.468e-01 / max=6.529e-01\n",
      "ll=24_model_ae_4 [1600, 400, 100, 24]\n",
      "min=5.202e-02 / mean=1.133e-01 / median=1.096e-01 / max=3.904e-01\n",
      "min=5.806e-02 / mean=1.597e-01 / median=1.371e-01 / max=7.366e-01\n",
      "ll=25_model_ae_0 [1600, 400, 100, 25]\n",
      "min=5.196e-02 / mean=1.096e-01 / median=1.055e-01 / max=3.236e-01\n",
      "min=5.475e-02 / mean=1.542e-01 / median=1.330e-01 / max=6.928e-01\n",
      "ll=25_model_ae_1 [1600, 400, 100, 25]\n",
      "min=5.428e-02 / mean=1.149e-01 / median=1.112e-01 / max=3.152e-01\n",
      "min=5.864e-02 / mean=1.641e-01 / median=1.349e-01 / max=7.148e-01\n",
      "ll=25_model_ae_2 [1600, 400, 100, 25]\n",
      "min=5.481e-02 / mean=1.240e-01 / median=1.212e-01 / max=2.681e-01\n",
      "min=5.769e-02 / mean=1.631e-01 / median=1.419e-01 / max=9.201e-01\n",
      "ll=25_model_ae_3 [1600, 400, 100, 25]\n",
      "min=5.607e-02 / mean=1.176e-01 / median=1.138e-01 / max=2.753e-01\n",
      "min=5.802e-02 / mean=1.664e-01 / median=1.430e-01 / max=6.086e-01\n",
      "ll=25_model_ae_4 [1600, 400, 100, 25]\n",
      "min=5.781e-02 / mean=1.174e-01 / median=1.136e-01 / max=2.744e-01\n",
      "min=6.021e-02 / mean=1.611e-01 / median=1.375e-01 / max=6.687e-01\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/last_layer/'\n",
    "model_filename_hard_prefix = 'll='\n",
    "model_filename_base = 'model_ae_'\n",
    "\n",
    "results_filename = 'relres_ae_ll'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "filename_cv = 'cv_indices.npz'\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "sizes_ll = range(1, sizes[-1]+1)\n",
    "nEpoch = [1000, 1000, 1000]\n",
    "batch_size = 200\n",
    "num_workers = 2\n",
    "n_splits = 5\n",
    "\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, labels = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize among samples\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "N = T.shape[1]\n",
    "\n",
    "# optimizer parameters (needed to initialize AE class before parameters loading)\n",
    "learning_rate = 0.0025\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-5\n",
    "optimizer = lambda params: torch.optim.Adam(params, lr=learning_rate, betas=betas, eps=eps)\n",
    "nls = [nn.ReLU()]+[nn.Sigmoid()]*(len(sizes))\n",
    "\n",
    "\n",
    "model_fname_list = os.listdir(model_dirname)\n",
    "model_fname_list = filter(lambda x: x.startswith(model_filename_hard_prefix), model_fname_list)\n",
    "model_fname_list = filter(lambda x: model_filename_base in x, model_fname_list)\n",
    "model_fname_list = sorted(model_fname_list, key=stringSplitByNumbers)\n",
    "\n",
    "relres_train = []\n",
    "relres_test = []\n",
    "for i_sz in xrange(len(sizes_ll)):\n",
    "    #current_size = sizes_ll[i_sz]\n",
    "    sizes_local = [N] + sizes[:-1] + [sizes_ll[i_sz]]\n",
    "    autoencoder = ae.AutoEncoder(sizes_local, nls, optimizer=optimizer, loss=nn.SmoothL1Loss)\n",
    "    relres_train_loc = []\n",
    "    relres_test_loc = []\n",
    "    for i_cv in xrange(n_splits):\n",
    "        num_model = i_sz*n_splits + i_cv\n",
    "        model_fname = model_fname_list[num_model]\n",
    "        print model_fname, sizes_local\n",
    "        autoencoder.load_state_dict(torch.load(model_dirname+model_fname))\n",
    "        _, tmp = ae.getStats(autoencoder, T[train_indices[i_cv]])\n",
    "        relres_train_loc.append(np.median(tmp))\n",
    "        _, tmp = ae.getStats(autoencoder, T[test_indices[i_cv]])\n",
    "        relres_test_loc.append(np.median(tmp))\n",
    "    relres_train.append(np.median(relres_train_loc))\n",
    "    relres_test.append(np.median(relres_test_loc))\n",
    "np.savez_compressed(model_dirname+results_filename, relres_train=relres_train, relres_test=relres_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate how size of last encoding layer affects results: encode data\n",
    "\n",
    "Here we use only one repeat of 5-fold CV\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_prefix = 'll='\n",
    "model_dirname = '../models/autoencoder/last_layer/'\n",
    "model_filename_prefix = 'model_ae_'\n",
    "filename_dataset = 'dataset.npz'\n",
    "save_filename_postfix = 'autoencoded_' + filename_dataset\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "num_workers = 2\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "\n",
    "for k in xrange(sizes[-1]):\n",
    "    sizes_ll = sizes[:-1] + [k+1]\n",
    "    model_full_prefix = model_prefix + str(k+1) + '_' + model_filename_prefix\n",
    "    save_filename = model_prefix+str(k+1)+'_'+save_filename_postfix\n",
    "    ae.encodeDataset(\n",
    "        df, sizes_ll, model_dirname, model_full_prefix,\n",
    "        data_dirname+save_filename, num_workers, return_result=0\n",
    "    )\n",
    "    print model_dirname+model_full_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate how size of last encoding layer affects results: predict with logistic regression\n",
    "\n",
    "Here we use only one repeat of 5-fold CV\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "model_prefix = 'll='\n",
    "model_dirname = '../models/autoencoder/last_layer/'\n",
    "model_filename_prefix = 'model_ae_'\n",
    "filename_dataset_base = 'autoencoded_dataset.npz'\n",
    "\n",
    "ll_max = 25\n",
    "n_splits = 5\n",
    "\n",
    "dirname_results = '../results/'\n",
    "filename_results = 'll_autoencoder+LR'\n",
    "\n",
    "filename_cv = 'cv_indices.npz'\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "\n",
    "\n",
    "tms = []\n",
    "#predict_train_all = []\n",
    "#predict_test_all = []\n",
    "\n",
    "accuracies = []\n",
    "f1s = []\n",
    "\n",
    "for l in xrange(ll_max):\n",
    "    print 'last layer size=%d' % (l+1)\n",
    "    filename_data = model_prefix+str(l+1)+'_'+filename_dataset_base\n",
    "    df = np.load(data_dirname+filename_data)\n",
    "    X, y = df['data'], df['label']\n",
    "    y = reshape(y, [-1, 1])\n",
    "    \n",
    "    tms_l = []\n",
    "    predict_train_l = []\n",
    "    predict_test_l = []\n",
    "\n",
    "    accuracies_l = []\n",
    "    f1s_l = []\n",
    "    for k in xrange(n_splits):\n",
    "        train_index = train_indices[k]\n",
    "        test_index = test_indices[k]\n",
    "\n",
    "        classifier = LogisticRegression(\n",
    "            penalty='l1', dual=False, tol=0.0001, C=1000.0, fit_intercept=True,\n",
    "            intercept_scaling=1, class_weight=None, random_state=None,\n",
    "            solver='saga', max_iter=1000, multi_class='multinomial', verbose=0,\n",
    "            warm_start=False, n_jobs=1\n",
    "        )\n",
    "\n",
    "        tic = time.clock();\n",
    "        classifier.fit(X[k][train_index], y[train_index])\n",
    "        toc = time.clock();\n",
    "\n",
    "        tms_loc = [toc-tic]\n",
    "\n",
    "        tic = time.clock()\n",
    "        predict_train = classifier.predict(X[k][train_index])\n",
    "        toc = time.clock()\n",
    "        tms_loc.append(toc-tic)\n",
    "        acc_loc = [accuracy_score(y[train_index], predict_train)]\n",
    "        f1_loc = [f1_score(y[train_index], predict_train, average='weighted')]\n",
    "        tic = time.clock()\n",
    "        predict_test = classifier.predict(X[k][test_index])\n",
    "        toc = time.clock()\n",
    "        acc_loc.append( accuracy_score(y[test_index], predict_test) )\n",
    "        f1_loc.append(f1_score(y[test_index], predict_test, average='weighted') )\n",
    "        #confusion_matrices.append(confusion_matrix(y[test_index], predict_test))\n",
    "        tms_loc.append(toc-tic)\n",
    "\n",
    "        accuracies_l.append(acc_loc)\n",
    "        f1s_l.append(f1_loc)\n",
    "        tms_l.append(tms_loc)\n",
    "        #predict_train_l.append( predict_train )\n",
    "        #predict_test_l.append( predict_test )\n",
    "        \n",
    "    tms.append(tms_l)\n",
    "    #predict_train_all.append(predict_train_l)\n",
    "    #predict_test_all.append(predict_test_l)\n",
    "\n",
    "    accuracies.append(accuracies_l)\n",
    "    f1s.append(f1s_l)\n",
    "np.savez_compressed(\n",
    "    dirname_results+filename_results, tms=tms,\n",
    "    acc=accuracies, f1=f1s\n",
    ")    \n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "print \"accuracies\"\n",
    "print np.median(accuracies, axis=1)\n",
    "print \"f1 measure\"\n",
    "print np.median(f1s, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier with encoded data\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "dirname_results = '../results/'\n",
    "filename_results = 'autoencoder+LR'\n",
    "data_filename = 'autoencoded_dataset.npz'\n",
    "data_test2_filename = 'autoencoded_test2.npz'\n",
    "\n",
    "filename_cv = 'cv_indices.npz'\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+data_test2_filename)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "df = np.load(data_dirname+data_filename)\n",
    "X, y = df['data'], df['label']\n",
    "y = reshape(y, [-1, 1])\n",
    "colnames = ['identity'] + ['V%d' % (i) for i in xrange(X.shape[-1])]\n",
    "\n",
    "tms = []\n",
    "predict_train_all = []\n",
    "predict_test_all = []\n",
    "predict_test2_all = []\n",
    "\n",
    "confusion_matrices = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "\n",
    "# correct label in the end\n",
    "predicted_probas_test = []\n",
    "predicted_probas_test2 = []\n",
    "for k in xrange(len(train_indices)):\n",
    "    print \"CV %d / %d\" % (k+1, len(train_indices))\n",
    "    train_index = train_indices[k]\n",
    "    test_index = test_indices[k]\n",
    "    \n",
    "    classifier = LogisticRegression(\n",
    "        penalty='l1', dual=False, tol=0.0001, C=1000.0, fit_intercept=True,\n",
    "        intercept_scaling=1, class_weight=None, random_state=None,\n",
    "        solver='saga', max_iter=1000, multi_class='multinomial', verbose=0,\n",
    "        warm_start=False, n_jobs=1\n",
    "    )\n",
    "    \n",
    "    tic = time.clock();\n",
    "    classifier.fit(X[k][train_index], y[train_index])\n",
    "    toc = time.clock();\n",
    "    \n",
    "    tms_loc = [toc-tic]\n",
    "    \n",
    "    tic = time.clock()\n",
    "    predict_train = classifier.predict(X[k][train_index])\n",
    "    toc = time.clock()\n",
    "    tms_loc.append(toc-tic)\n",
    "    acc_loc = [accuracy_score(y[train_index], predict_train)]\n",
    "    f1_loc = [f1_score(y[train_index], predict_train, average='weighted')]\n",
    "    tic = time.clock()\n",
    "    predict_test = classifier.predict(X[k][test_index])\n",
    "    toc = time.clock()\n",
    "    acc_loc.append( accuracy_score(y[test_index], predict_test) )\n",
    "    f1_loc.append(f1_score(y[test_index], predict_test, average='weighted') )\n",
    "    confusion_matrices.append(confusion_matrix(y[test_index], predict_test))\n",
    "    tms_loc.append(toc-tic)\n",
    "    \n",
    "    tmp = reshape(np.array(y[test_index]), [-1, 1])\n",
    "    tmp = np.hstack([classifier.predict_proba(X[k][test_index]), tmp])\n",
    "    predicted_probas_test.append( tmp.copy() )\n",
    "    tmp = reshape(np.array(y_test2), [-1, 1])\n",
    "    tmp = np.hstack([classifier.predict_proba(X_test2[k]), tmp])\n",
    "    predicted_probas_test2.append( tmp.copy() )\n",
    "    \n",
    "    predict_test2 = classifier.predict(X_test2[k])\n",
    "    acc_loc.append( accuracy_score(y_test2, predict_test2) )\n",
    "    f1_loc.append(f1_score(y_test2, predict_test2, average='weighted') )\n",
    "    \n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    tms.append(tms_loc)\n",
    "    predict_train_all.append( predict_train )\n",
    "    predict_test_all.append( predict_test )\n",
    "    predict_test2_all.append( predict_test2 )\n",
    "    np.savez_compressed(\n",
    "        dirname_results+filename_results, tms=tms, predict_train=predict_train_all,\n",
    "        predict_test=predict_test_all, predict_test2=predict_test2_all, test_indices=test_indices,\n",
    "        train_indices=train_indices, y_test2=y_test2.T, y=y, confusion_matrices=confusion_matrices,\n",
    "        acc=accuracies, f1=f1s, predicted_probas_test=predicted_probas_test,\n",
    "        predicted_probas_test2=predicted_probas_test2\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "print \"accuracies\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"f1 measure\"\n",
    "print np.median(f1s, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes classifier with encoded data\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dirname = '../data/'\n",
    "dirname_results = '../results/'\n",
    "filename_results = 'autoencoder+NB'\n",
    "data_filename = 'autoencoded_dataset.npz'\n",
    "data_test2_filename = 'autoencoded_test2.npz'\n",
    "\n",
    "filename_cv = 'cv_indices.npz'\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+data_test2_filename)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "df = np.load(data_dirname+data_filename)\n",
    "X, y = df['data'], df['label']\n",
    "y = reshape(y, [-1, 1])\n",
    "colnames = ['identity'] + ['V%d' % (i) for i in xrange(X.shape[-1])]\n",
    "\n",
    "tms = []\n",
    "predict_train_all = []\n",
    "predict_test_all = []\n",
    "predict_test2_all = []\n",
    "\n",
    "# correct label in the end\n",
    "predicted_probas_test = []\n",
    "predicted_probas_test2 = []\n",
    "\n",
    "confusion_matrices = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "\n",
    "for k in xrange(len(train_indices)):\n",
    "    train_index = train_indices[k]\n",
    "    test_index = test_indices[k]\n",
    "    \n",
    "    classifier = GaussianNB()\n",
    "    \n",
    "    tic = time.clock();\n",
    "    classifier.fit(X[k][train_index], y[train_index])\n",
    "    toc = time.clock();\n",
    "    \n",
    "    tms_loc = [toc-tic]\n",
    "    \n",
    "    tic = time.clock()\n",
    "    predict_train = classifier.predict(X[k][train_index])\n",
    "    toc = time.clock()\n",
    "    tms_loc.append(toc-tic)\n",
    "    acc_loc = [accuracy_score(y[train_index], predict_train)]\n",
    "    f1_loc = [f1_score(y[train_index], predict_train, average='weighted')]\n",
    "    tic = time.clock()\n",
    "    predict_test = classifier.predict(X[k][test_index])\n",
    "    toc = time.clock()\n",
    "    acc_loc.append( accuracy_score(y[test_index], predict_test) )\n",
    "    f1_loc.append(f1_score(y[test_index], predict_test, average='weighted') )\n",
    "    confusion_matrices.append(confusion_matrix(y[test_index], predict_test))\n",
    "    tms_loc.append(toc-tic)\n",
    "    predict_test2 = classifier.predict(X_test2[k])\n",
    "    acc_loc.append( accuracy_score(y_test2, predict_test2) )\n",
    "    f1_loc.append(f1_score(y_test2, predict_test2, average='weighted') )\n",
    "    \n",
    "    tmp = reshape(np.array(y[test_index]), [-1, 1])\n",
    "    tmp = np.hstack([classifier.predict_proba(X[k][test_index]), tmp])\n",
    "    predicted_probas_test.append( tmp.copy() )\n",
    "    tmp = reshape(np.array(y_test2), [-1, 1])\n",
    "    tmp = np.hstack([classifier.predict_proba(X_test2[k]), tmp])\n",
    "    predicted_probas_test2.append( tmp.copy() )\n",
    "    \n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    tms.append(tms_loc)\n",
    "    predict_train_all.append( predict_train )\n",
    "    predict_test_all.append( predict_test )\n",
    "    predict_test2_all.append( predict_test2 )\n",
    "    np.savez_compressed(\n",
    "        dirname_results+filename_results, tms=tms, predict_train=predict_train_all,\n",
    "        predict_test=predict_test_all, predict_test2=predict_test2_all, test_indices=test_indices,\n",
    "        train_indices=train_indices, y_test2=y_test2.T, y=y, confusion_matrices=confusion_matrices,\n",
    "        acc=accuracies, f1=f1s, predicted_probas_test=predicted_probas_test,\n",
    "        predicted_probas_test2=predicted_probas_test2\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "print \"accuracies\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"f1 measure\"\n",
    "print np.median(f1s, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Bayesian classifier with bnlearn\n",
    "\n",
    "To reproduce this part of research, user should additionally install kernel for R (please see [Chemfin notebook](../Chemfin.ipynb) ) and bnlearn package.\n",
    "\n",
    "[Back to contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from computational_utils import reshape\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "rpy2.robjects.pandas2ri.activate()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install bnlearn package, run code in the following cell. Otherwise please skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils = importr('utils')\n",
    "utils.install_packages('bnlearn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn structure, fit training set and predict labels for training, validation and test2 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnlearn = importr('bnlearn')\n",
    "\n",
    "data_dirname = '../data/'\n",
    "dirname_results = '../results/'\n",
    "filename_results = 'autoencoder+HBN'\n",
    "data_filename = 'autoencoded_dataset.npz'\n",
    "data_test2_filename = 'autoencoded_test2.npz'\n",
    "\n",
    "filename_cv = 'cv_indices.npz'\n",
    "df = np.load(data_dirname+filename_cv)\n",
    "test_indices, train_indices = df['test_indices'], df['train_indices']\n",
    "\n",
    "df = np.load(data_dirname+data_test2_filename)\n",
    "X_test2, y_test2 = df['data'], df['label']\n",
    "y_test2 = reshape(y_test2, [-1, 1])\n",
    "\n",
    "df = np.load(data_dirname+data_filename)\n",
    "X, y = df['data'], df['label']\n",
    "y = reshape(y, [-1, 1])\n",
    "colnames = ['identity'] + ['V%d' % (i) for i in xrange(X.shape[-1])]\n",
    "\n",
    "tms = []\n",
    "predict_train_all = []\n",
    "predict_test_all = []\n",
    "predict_test2_all = []\n",
    "\n",
    "confusion_matrices = []\n",
    "accuracies = []\n",
    "f1s = []\n",
    "\n",
    "for k in xrange(len(train_indices)):\n",
    "    train_index = train_indices[k]\n",
    "    test_index = test_indices[k]\n",
    "    dataset_train = np.hstack([y[train_index], X[k, train_index, :]])\n",
    "    dataset_train = pd.DataFrame(dataset_train, columns=colnames)\n",
    "    dataset_train['identity'] = dataset_train['identity'].apply(str)\n",
    "    dmap = dataset_train.iloc[:, 0].values\n",
    "    dmap = np.unique(dmap)\n",
    "    dataset_test = np.hstack([y[test_index], X[k, test_index, :]])\n",
    "    dataset_test = pd.DataFrame(dataset_test, columns=colnames)\n",
    "    dataset_test['identity'] = dataset_test['identity'].apply(str)\n",
    "    dataset_test2 = np.hstack([y_test2, X_test2[k, :, :]])\n",
    "    dataset_test2 = pd.DataFrame(dataset_test2, columns=colnames)\n",
    "    dataset_test2['identity'] = dataset_test2['identity'].apply(str)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    hBN_structure = bnlearn.mmhc(dataset_train)\n",
    "    toc = time.clock()\n",
    "    tms_loc = [toc-tic]\n",
    "    fitted_bn = bnlearn.bn_fit(hBN_structure, dataset_train, method='mle')\n",
    "    \n",
    "    tic = time.clock()\n",
    "    predict_train = bnlearn.predict_bn_fit(\n",
    "        fitted_bn, node='identity', data=dataset_train.iloc[:, 1:], method='bayes-lw'\n",
    "    )\n",
    "    \n",
    "    predict_test = bnlearn.predict_bn_fit(\n",
    "        fitted_bn, node='identity', data=dataset_test.iloc[:, 1:], method='bayes-lw'\n",
    "    )\n",
    "    \n",
    "    toc = time.clock()\n",
    "    predict_train = np.array(predict_train)\n",
    "    predict_train = dmap[predict_train]\n",
    "    acc_loc = [accuracy_score(y[train_index], predict_train)]\n",
    "    f1_loc = [f1_score(y[train_index], predict_train, average='weighted')]\n",
    "    predict_test = np.array(predict_test)\n",
    "    predict_test = dmap[predict_test]\n",
    "    acc_loc.append( accuracy_score(y[test_index], predict_test) )\n",
    "    f1_loc.append(f1_score(y[test_index], predict_test, average='weighted') )\n",
    "    tms_loc.append(toc-tic)\n",
    "    predict_test2 = bnlearn.predict_bn_fit(\n",
    "        fitted_bn, node='identity', data=dataset_test2.iloc[:, 1:], method='bayes-lw'\n",
    "    )\n",
    "    predict_test2 = np.array(predict_test2)\n",
    "    predict_test2 = dmap[predict_test2]\n",
    "    acc_loc.append( accuracy_score(y_test2, predict_test2) )\n",
    "    f1_loc.append(f1_score(y_test2, predict_test2, average='weighted') )\n",
    "    tms.append(tms_loc)\n",
    "    predict_train_all.append( predict_train )\n",
    "    predict_test_all.append( predict_test )\n",
    "    predict_test2_all.append( predict_test2 )\n",
    "    \n",
    "    accuracies.append(acc_loc)\n",
    "    f1s.append(f1_loc)\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        dirname_results+filename_results, tms=tms, predict_train=predict_train_all,\n",
    "        predict_test=predict_test_all, predict_test2=predict_test2_all, test_indices=test_indices,\n",
    "        train_indices=train_indices, y_test2=y_test2.T, y=y\n",
    "    )\n",
    "accuracies = np.array(accuracies)\n",
    "f1s = np.array(f1s)\n",
    "print \"accuracies\"\n",
    "print np.median(accuracies, axis=0)\n",
    "print \"f1 measure\"\n",
    "print np.median(f1s, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder learned on whole database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Errors on input set (2263 samples): \n",
      "min=5.964e-02 / mean=1.099e-01 / median=1.061e-01 / max=2.278e-01\n",
      "(2) Errors on input set (2263 samples): \n",
      "min=4.737e-02 / mean=8.862e-02 / median=8.615e-02 / max=1.804e-01\n",
      "(3) Errors on input set (2263 samples): \n",
      "min=5.128e-02 / mean=1.058e-01 / median=1.013e-01 / max=5.210e-01\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/'\n",
    "model_filename_prefix = 'full_data_model_ae_'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "nEpoch = [1000, 1000, 1000]\n",
    "batch_size = 200\n",
    "num_workers = 14\n",
    "\n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, labels = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize among samples\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "\n",
    "learning_rate = 0.0025\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-5\n",
    "optimizer = lambda params: torch.optim.Adam(params, lr=learning_rate, betas=betas, eps=eps) # Sparse\n",
    "N = T.shape[1]\n",
    "# AE structure + instance\n",
    "nls = [nn.ReLU()]+[nn.Sigmoid()]*len(sizes)\n",
    "sizes = [N] + sizes\n",
    "dataset = torch.from_numpy(T.copy())\n",
    "data = ae.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "times = np.zeros([len(sizes)-1, 2])\n",
    "# Nlevels, l1/l2\n",
    "stats_integral = np.zeros([len(sizes)-1])\n",
    "# N samples, Nlevels, l1/l2\n",
    "sample_stats = np.zeros([len(sizes)-1, T.shape[0]])\n",
    "# Ntrain, Nlevels, nEpoch\n",
    "loss_values = np.zeros([len(sizes)-1, max(nEpoch)])\n",
    "for k in xrange(len(sizes)-1):\n",
    "    autoencoder = ae.AutoEncoder(sizes=sizes[:k+2], nls=nls[:k+2], optimizer=optimizer, loss=nn.SmoothL1Loss)\n",
    "    if k > 0:\n",
    "        for i in xrange(k):\n",
    "            autoencoder.Encoder[2*i].weight = weights[2*i]\n",
    "            autoencoder.Encoder[2*i].bias = biases[2*i]\n",
    "            autoencoder.Decoder[2*(i+1)].weight = weights[2*i+1]\n",
    "            autoencoder.Decoder[2*(i+1)].bias = biases[2*i+1]\n",
    "    t1_time = time.time(); t1_clock = time.clock()\n",
    "    loss_values_level = autoencoder.fit(data, nEpoch[k], verbose=0)\n",
    "    t2_clock = time.clock(); t2_time = time.time()\n",
    "    times[k, 0] = t2_time-t1_time\n",
    "    times[k, 1] = t2_clock-t1_clock\n",
    "    torch.save(autoencoder.state_dict(), model_dirname+model_filename_prefix)\n",
    "    print '(%d) Errors on input set (%d samples): ' % (k+1, T.shape[0])\n",
    "    stats_level = ae.getStats(autoencoder, T)\n",
    "\n",
    "    stats_integral[k] = stats_level[0]\n",
    "    sample_stats[k] = stats_level[1]\n",
    "    loss_values[k, :nEpoch[k]] = loss_values_level\n",
    "    np.savez_compressed(\n",
    "        model_dirname+'full_ae_stats', stats_integral=stats_integral,\n",
    "        loss_values=loss_values,\n",
    "        sample_stats=sample_stats, nEpoch=nEpoch, times=times\n",
    "    )\n",
    "    # test on train/valid. sets\n",
    "    if k < (len(sizes)-2):\n",
    "        weights, biases = [], []\n",
    "        for i in xrange(k+1):\n",
    "            weights.append( copy.deepcopy(autoencoder.Encoder[2*i].weight) )\n",
    "            weights.append( copy.deepcopy(autoencoder.Decoder[2*i].weight) )\n",
    "            biases.append( copy.deepcopy(autoencoder.Encoder[2*i].bias) )\n",
    "            biases.append( copy.deepcopy(autoencoder.Decoder[2*i].bias) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded with full_data_model_ae_. Comp.time=0.47915 s\n"
     ]
    }
   ],
   "source": [
    "data_dirname = '../data/'\n",
    "model_dirname = '../models/autoencoder/'\n",
    "model_fname = 'full_data_model_ae_'\n",
    "save_filename = 'full_dataset_autoencoded'\n",
    "\n",
    "filename_dataset = 'dataset.npz'\n",
    "\n",
    "sizes = [400, 100, 25]\n",
    "nEpoch = [1000, 1000, 1000]\n",
    "batch_size = 200\n",
    "num_workers = 14\n",
    "\n",
    "resultsTime = []\n",
    "# optimizer parameters\n",
    "learning_rate = 0.0025\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-5\n",
    "optimizer = lambda params: torch.optim.Adam(params, lr=learning_rate, betas=betas, eps=eps)\n",
    "    \n",
    "df = np.load(data_dirname+filename_dataset)\n",
    "T, y = df['data'], df['label']\n",
    "# unfold into matrix\n",
    "T = reshape(T, [T.shape[0], -1])\n",
    "# normalize among samples\n",
    "T /= np.linalg.norm(T, axis=1, keepdims=1)\n",
    "    \n",
    "    \n",
    "N = T.shape[1]\n",
    "sizes = [N] + sizes\n",
    "\n",
    "nls = [nn.ReLU()]+[nn.Sigmoid()]*(len(sizes)-1)\n",
    "\n",
    "autoencoder = ae.AutoEncoder(sizes, nls, optimizer=optimizer, loss=nn.SmoothL1Loss)\n",
    "autoencoder.load_state_dict(torch.load(model_dirname+model_fname))\n",
    "\n",
    "X = Variable(torch.from_numpy(T.copy()))\n",
    "tic = time.clock()\n",
    "Y = autoencoder.encode(X)\n",
    "toc = time.clock()\n",
    "X = Y.data.numpy()\n",
    "resultsTime = toc-tic\n",
    "print \"encoded with %s. Comp.time=%.5f s\" % (model_fname, resultsTime)\n",
    "np.savez_compressed(data_dirname+save_filename, data=X, label=y, time=resultsTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
